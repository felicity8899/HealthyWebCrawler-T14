2016-06-17 12:34:42 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 12:34:42 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 12:34:42 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 12:34:42 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 12:34:42 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 12:34:42 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 12:34:42 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 12:34:42 [scrapy] INFO: Spider opened
2016-06-17 12:34:42 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 12:34:42 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 12:34:43 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 12:34:43 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 12:34:43 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219837',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253975',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121770',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14660',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:44 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24331',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'378879', u'1100', u'98666'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341861',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321000',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29796',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:34:45 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add(results)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 865, in add
    message.append(self._build_doc(doc, boost=boost, fieldUpdates=fieldUpdates))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 790, in _build_doc
    for key, value in doc.items():
AttributeError: 'str' object has no attribute 'items'
2016-06-17 12:34:45 [scrapy] INFO: Closing spider (finished)
2016-06-17 12:34:45 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324114,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 19, 34, 45, 967654),
 'log_count/DEBUG': 100,
 'log_count/ERROR': 48,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 19, 34, 42, 802303)}
2016-06-17 12:34:45 [scrapy] INFO: Spider closed (finished)
2016-06-17 12:42:01 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 12:42:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 12:42:01 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 12:42:01 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 12:42:01 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 12:42:01 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 12:42:01 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 12:42:01 [scrapy] INFO: Spider opened
2016-06-17 12:42:01 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 12:42:01 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 12:42:02 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 12:42:02 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 12:42:02 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:02 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.008 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341861',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321000',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29796',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219838',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:03 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:03 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24331',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14660',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121770',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253975',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:42:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:42:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:42:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:42:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:42:04 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:42:04 [scrapy] INFO: Closing spider (finished)
2016-06-17 12:42:04 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324097,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 19, 42, 4, 568335),
 'log_count/DEBUG': 244,
 'log_count/ERROR': 96,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 19, 42, 1, 311031)}
2016-06-17 12:42:04 [scrapy] INFO: Spider closed (finished)
2016-06-17 12:44:18 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 12:44:18 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 12:44:19 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 12:44:19 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 12:44:19 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 12:44:19 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 12:44:19 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 12:44:19 [scrapy] INFO: Spider opened
2016-06-17 12:44:19 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 12:44:19 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 12:44:19 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 12:44:19 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 12:44:20 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:20 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:20 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:20 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:20 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:20 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 12:44:20 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:20 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.005 seconds, with status 404
2016-06-17 12:44:20 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:20 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29796',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321000',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341861',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.004 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219838',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24331',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:21 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:21 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14660',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121770',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253975',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:44:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:44:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:44:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 12:44:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 404
2016-06-17 12:44:22 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:44:22 [scrapy] INFO: Closing spider (finished)
2016-06-17 12:44:22 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324123,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 19, 44, 22, 615601),
 'log_count/DEBUG': 244,
 'log_count/ERROR': 96,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 19, 44, 19, 125957)}
2016-06-17 12:44:22 [scrapy] INFO: Spider closed (finished)
2016-06-17 12:53:50 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 12:53:50 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 12:53:50 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 12:53:50 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 12:53:50 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 12:53:50 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 12:53:50 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 12:53:50 [scrapy] INFO: Spider opened
2016-06-17 12:53:50 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 12:53:50 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 12:53:51 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 12:53:51 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 12:53:51 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b737ed0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b737ed0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b737ed0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (2): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b14d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b14d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121770',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b14d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (3): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1210>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1210>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253975',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1210>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (4): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7b50>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7b50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29796',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7b50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (5): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c690>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c690>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c690>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (6): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c76d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c76d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c76d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (7): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c550>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c550>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c550>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (8): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7110>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7110>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'378879', u'1100', u'98666'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7110>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (9): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c2d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c2d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c2d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (10): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7350>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7350>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7350>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (11): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7390>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7390>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7390>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (12): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3cd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3cd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3cd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (13): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3d90>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3d90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3d90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (14): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3cd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3cd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3cd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (15): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3a90>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3a90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3a90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:52 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:52 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (16): localhost
2016-06-17 12:53:52 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7110>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7110>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:52 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7110>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (17): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b61cd50>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b61cd50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b61cd50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (18): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1290>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1290>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1290>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (19): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b68ab50>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b68ab50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'39312', u'71936'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b68ab50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (20): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7950>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7950>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7950>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (21): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3610>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3610>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3610>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (22): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b66d8d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b66d8d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b66d8d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (23): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1a10>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1a10>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1a10>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (24): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7c50>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7c50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c7c50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (25): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1990>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1990>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1990>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (26): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1dd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1dd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24331',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6b1dd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (27): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3bd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3bd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3bd0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (28): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3650>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3650>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3650>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (29): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3e90>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3e90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3e90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (30): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b58ca90>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b58ca90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b58ca90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (31): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b5ab0d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b5ab0d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b5ab0d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (32): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b58ce50>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b58ce50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b58ce50>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (33): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c650>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c650>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b71c650>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (34): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3a10>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3a10>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3a10>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (35): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b5cb650>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b5cb650>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b5cb650>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (36): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3ed0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3ed0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3ed0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (37): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b7a24d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b7a24d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14660',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b7a24d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (38): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b68a690>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b68a690>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b68a690>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (39): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b7a2390>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b7a2390>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b7a2390>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (40): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3710>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3710>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3710>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (41): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3f90>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3f90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6a3f90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (42): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b5cb6d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b5cb6d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b5cb6d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (43): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b61c510>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b61c510>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321000',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b61c510>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (44): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b785f10>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b785f10>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b785f10>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (45): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b61cf90>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b61cf90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341861',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b61cf90>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (46): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3290>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3290>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3290>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:53 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:53 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (47): localhost
2016-06-17 12:53:53 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3110>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3110>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:53 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b6c3110>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:53:54 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:53:54 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:53:54 [pysolr] DEBUG: Starting request to 'http://localhost:9001/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:53:54 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (48): localhost
2016-06-17 12:53:54 [pysolr] ERROR: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b66d4d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 361, in _send_request
    timeout=self.timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 518, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/sessions.py", line 585, in send
    r = adapter.send(request, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/requests/adapters.py", line 467, in send
    raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b66d4d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:54 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 370, in _send_request
    raise SolrError(error_message % params)
SolrError: Failed to connect to server at 'http://localhost:9001/solr/default/update/?commit=true', are you sure that URL is correct? Checking it in a browser might help: HTTPConnectionPool(host='localhost', port=9001): Max retries exceeded with url: /solr/default/update/?commit=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7efd6b66d4d0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2016-06-17 12:53:54 [scrapy] INFO: Closing spider (finished)
2016-06-17 12:53:54 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324188,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 19, 53, 54, 146757),
 'log_count/DEBUG': 196,
 'log_count/ERROR': 96,
 'log_count/INFO': 55,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 19, 53, 50, 524325)}
2016-06-17 12:53:54 [scrapy] INFO: Spider closed (finished)
2016-06-17 12:54:14 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 12:54:14 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 12:54:14 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 12:54:14 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 12:54:14 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 12:54:14 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 12:54:14 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 12:54:14 [scrapy] INFO: Spider opened
2016-06-17 12:54:14 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 12:54:14 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 12:54:15 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 12:54:15 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 12:54:15 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.007 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.005 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341861',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321000',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29796',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'364690', u'394794', u'85039', u'325526'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:16 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:16 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24331',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253977',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121770',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:54:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:54:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:54:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/default/update/?commit=true HTTP/1.1" 404 252
2016-06-17 12:54:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 12:54:17 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 111, in process_item
    self.solr.add([results])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:54:17 [scrapy] INFO: Closing spider (finished)
2016-06-17 12:54:17 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324096,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 19, 54, 17, 754590),
 'log_count/DEBUG': 244,
 'log_count/ERROR': 96,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 19, 54, 14, 472154)}
2016-06-17 12:54:17 [scrapy] INFO: Spider closed (finished)
2016-06-17 12:55:32 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 12:55:32 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 12:55:32 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 12:55:32 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 12:55:32 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 12:55:32 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 12:55:32 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 12:55:32 [scrapy] INFO: Spider opened
2016-06-17 12:55:32 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 12:55:32 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 12:55:33 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 12:55:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 12:55:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/108048>
{'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1045>
{'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4928>
{'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1359>
{'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5314>
{'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/39086>
{'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1023>
{'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253977',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1122>
{'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121770',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/125>
{'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29837>
{'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/58634>
{'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1338>
{'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24331',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/323>
{'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'102772', u'396151', u'87320', u'10408'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/374173>
{'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/219>
{'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/7055>
{'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4888>
{'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1984', u'69660', u'330724', u'360'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/31322>
{'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/297>
{'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/54719>
{'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/13900>
{'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1109>
{'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
2016-06-17 12:55:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/8543>
{'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/22704>
{'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/419543>
{'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/10411>
{'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/9744>
{'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/118>
{'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1294>
{'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/2094>
{'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1131>
{'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/497>
{'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1326>
{'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5>
{'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/19903>
{'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/96928>
{'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1127>
{'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341861',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/329>
{'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321000',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/55358>
{'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/346>
{'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1363>
{'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29796',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
2016-06-17 12:55:35 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/109>
{'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1357>
{'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/270422>
{'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1110>
{'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/98>
{'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/332>
{'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
2016-06-17 12:55:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71936>
{'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
2016-06-17 12:55:35 [scrapy] INFO: Closing spider (finished)
2016-06-17 12:55:35 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324122,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 19, 55, 35, 727867),
 'item_scraped_count': 48,
 'log_count/DEBUG': 100,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 19, 55, 32, 388612)}
2016-06-17 12:55:35 [scrapy] INFO: Spider closed (finished)
2016-06-17 12:57:04 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 12:57:04 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 12:57:04 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 12:57:04 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 12:57:04 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 12:57:04 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 12:57:04 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 12:57:04 [scrapy] INFO: Spider opened
2016-06-17 12:57:05 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 12:57:05 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 12:57:05 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 12:57:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 12:57:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:06 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 12:57:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.005 seconds, with status 404
2016-06-17 12:57:06 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:06 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:06 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:06 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:06 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:06 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341861',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:06 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:06 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29796',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.003 seconds, with status 404
2016-06-17 12:57:06 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:06 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321000',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24331',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:07 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:07 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.003 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.003 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121770',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253977',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:57:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/default/select/?q=bananas&wt=json HTTP/1.1" 404 252
2016-06-17 12:57:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/default/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 404
2016-06-17 12:57:08 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 12:57:08 [scrapy] INFO: Closing spider (finished)
2016-06-17 12:57:08 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324075,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 19, 57, 8, 486649),
 'log_count/DEBUG': 148,
 'log_count/ERROR': 96,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 19, 57, 5, 205)}
2016-06-17 12:57:08 [scrapy] INFO: Spider closed (finished)
2016-06-17 12:58:10 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 12:58:10 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 12:58:10 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 12:58:10 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 12:58:10 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 12:58:10 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 12:58:10 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 12:58:10 [scrapy] INFO: Spider opened
2016-06-17 12:58:10 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 12:58:10 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 12:58:10 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 12:58:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 12:58:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:11 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:11 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 12:58:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:11 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 12:58:11 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341861',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29796',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321000',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.003 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.003 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.003 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.003 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.003 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24331',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.003 seconds, with status 200
2016-06-17 12:58:12 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:13 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:13 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:13 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'378879', u'1100', u'98666'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:58:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:13 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:13 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121770',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:13 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253977',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:13 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:13 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body ''...
2016-06-17 12:58:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/ HTTP/1.1" 200 None
2016-06-17 12:58:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/select/?q=bananas&wt=json' (get) with body '' in 0.002 seconds, with status 200
2016-06-17 12:58:13 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.search('bananas')
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 711, in search
    decoded = self.decoder.decode(response)
  File "/usr/lib/python2.7/json/decoder.py", line 364, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/lib/python2.7/json/decoder.py", line 382, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded
2016-06-17 12:58:13 [scrapy] INFO: Closing spider (finished)
2016-06-17 12:58:13 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324118,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 19, 58, 13, 222253),
 'log_count/DEBUG': 148,
 'log_count/ERROR': 48,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 19, 58, 10, 152714)}
2016-06-17 12:58:13 [scrapy] INFO: Spider closed (finished)
2016-06-17 12:59:31 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 12:59:31 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 12:59:31 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 12:59:31 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 12:59:31 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 12:59:31 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 12:59:31 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 12:59:31 [scrapy] INFO: Spider opened
2016-06-17 12:59:31 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 12:59:31 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 12:59:32 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 12:59:32 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 12:59:32 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.004 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'364690', u'394794', u'85039', u'325526'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253977',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121770',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:33 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:33 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24331',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'378879', u'1100', u'98666'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341862',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321000',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29796',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 12:59:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 12:59:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 12:59:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/ HTTP/1.1" 405 319
2016-06-17 12:59:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/#/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 405
2016-06-17 12:59:34 [pysolr] ERROR: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 405): [Reason: Error 405 HTTP method POST is not supported by this URL]
2016-06-17 12:59:34 [scrapy] INFO: Closing spider (finished)
2016-06-17 12:59:34 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324097,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 19, 59, 34, 795631),
 'log_count/DEBUG': 244,
 'log_count/ERROR': 96,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 19, 59, 31, 651594)}
2016-06-17 12:59:34 [scrapy] INFO: Spider closed (finished)
2016-06-17 13:00:37 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 13:00:37 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 13:00:37 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 13:00:37 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 13:00:37 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 13:00:37 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 13:00:37 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 13:00:37 [scrapy] INFO: Spider opened
2016-06-17 13:00:37 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 13:00:37 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 13:00:38 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 13:00:39 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 13:00:39 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.005 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29796',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121770',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:40 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.004 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253977',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.003 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24331',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'378879', u'1100', u'98666'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341862',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321000',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:00:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:00:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:00:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/update/?commit=true HTTP/1.1" 404 244
2016-06-17 13:00:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/update/?commit=true' (post) with body 'u'<add><do' in 0.002 seconds, with status 404
2016-06-17 13:00:41 [pysolr] ERROR: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 113, in process_item
    print self.solr.add([{'bananas': '1'}])
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 875, in add
    overwrite=overwrite, handler=handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 471, in _update
    return self._send_request('post', path, message, {'Content-type': 'text/xml; charset=utf-8'})
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 404): [Reason: Error 404 Not Found]
2016-06-17 13:00:41 [scrapy] INFO: Closing spider (finished)
2016-06-17 13:00:41 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324112,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 20, 0, 41, 921388),
 'log_count/DEBUG': 244,
 'log_count/ERROR': 96,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 20, 0, 37, 541361)}
2016-06-17 13:00:41 [scrapy] INFO: Spider closed (finished)
2016-06-17 13:18:38 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 13:18:38 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 13:18:38 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 13:18:38 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 13:18:38 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 13:18:38 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 13:18:38 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 13:18:38 [scrapy] INFO: Spider opened
2016-06-17 13:18:38 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 13:18:38 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 13:18:39 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 13:18:39 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 13:18:39 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:40 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:40 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 13:18:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.800 seconds, with status 200
2016-06-17 13:18:41 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/39086>
{'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.537 seconds, with status 200
2016-06-17 13:18:41 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1359>
{'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:42 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:42 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.529 seconds, with status 200
2016-06-17 13:18:42 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/10411>
{'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
2016-06-17 13:18:42 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:42 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:42 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:42 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:42 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.498 seconds, with status 200
2016-06-17 13:18:42 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5314>
{'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
2016-06-17 13:18:42 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:42 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:42 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:43 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:43 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.541 seconds, with status 200
2016-06-17 13:18:43 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/7055>
{'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
2016-06-17 13:18:43 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:43 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:43 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:43 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:43 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.631 seconds, with status 200
2016-06-17 13:18:43 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/125>
{'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
2016-06-17 13:18:43 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:43 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:43 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:44 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:44 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.558 seconds, with status 200
2016-06-17 13:18:44 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1122>
{'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121772',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
2016-06-17 13:18:44 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:44 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:44 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:45 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:45 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.538 seconds, with status 200
2016-06-17 13:18:45 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1023>
{'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253978',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
2016-06-17 13:18:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:45 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:45 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:45 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:45 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.493 seconds, with status 200
2016-06-17 13:18:45 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4928>
{'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
2016-06-17 13:18:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:45 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:45 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:45 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:45 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:46 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 150
2016-06-17 13:18:46 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 1.087 seconds, with status 200
2016-06-17 13:18:46 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/419543>
{'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
2016-06-17 13:18:46 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:46 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:46 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:47 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:47 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.487 seconds, with status 200
2016-06-17 13:18:47 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/9744>
{'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
2016-06-17 13:18:47 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:47 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:47 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:47 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:47 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.491 seconds, with status 200
2016-06-17 13:18:47 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1294>
{'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
2016-06-17 13:18:47 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:47 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:47 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:48 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.569 seconds, with status 200
2016-06-17 13:18:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/219>
{'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
2016-06-17 13:18:48 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:48 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:48 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.569 seconds, with status 200
2016-06-17 13:18:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/497>
{'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
2016-06-17 13:18:48 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:48 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:49 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.597 seconds, with status 200
2016-06-17 13:18:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/2094>
{'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
2016-06-17 13:18:49 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:49 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:50 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:50 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.587 seconds, with status 200
2016-06-17 13:18:50 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1131>
{'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
2016-06-17 13:18:50 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:50 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:50 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:50 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:50 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.657 seconds, with status 200
2016-06-17 13:18:50 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1326>
{'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
2016-06-17 13:18:50 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:50 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:50 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:50 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:50 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:50 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:50 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:50 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:50 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:50 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:50 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:51 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:51 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.475 seconds, with status 200
2016-06-17 13:18:51 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4888>
{'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
2016-06-17 13:18:51 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:51 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:51 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:52 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 150
2016-06-17 13:18:52 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 1.006 seconds, with status 200
2016-06-17 13:18:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/297>
{'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
2016-06-17 13:18:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:52 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:52 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:52 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.471 seconds, with status 200
2016-06-17 13:18:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/54719>
{'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
2016-06-17 13:18:52 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:52 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:52 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:53 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:53 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.576 seconds, with status 200
2016-06-17 13:18:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/13900>
{'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
2016-06-17 13:18:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:53 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:53 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:53 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.585 seconds, with status 200
2016-06-17 13:18:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1109>
{'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
2016-06-17 13:18:53 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:53 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:53 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:54 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:54 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.548 seconds, with status 200
2016-06-17 13:18:54 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/8543>
{'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
2016-06-17 13:18:54 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:54 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:54 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:54 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:54 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.570 seconds, with status 200
2016-06-17 13:18:54 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29837>
{'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
2016-06-17 13:18:54 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:54 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:54 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:55 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:55 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.509 seconds, with status 200
2016-06-17 13:18:55 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/58634>
{'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
2016-06-17 13:18:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:18:55 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:55 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:55 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:56 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:56 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.689 seconds, with status 200
2016-06-17 13:18:56 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/31322>
{'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
2016-06-17 13:18:56 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:56 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:56 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:56 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:56 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.532 seconds, with status 200
2016-06-17 13:18:56 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1338>
{'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24332',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
2016-06-17 13:18:56 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:56 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:56 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:57 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 150
2016-06-17 13:18:57 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 1.052 seconds, with status 200
2016-06-17 13:18:57 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/323>
{'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
2016-06-17 13:18:57 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:57 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:57 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:58 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:58 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.485 seconds, with status 200
2016-06-17 13:18:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/374173>
{'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
2016-06-17 13:18:58 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:58 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:58 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:58 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:58 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.673 seconds, with status 200
2016-06-17 13:18:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/22704>
{'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
2016-06-17 13:18:58 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:58 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:58 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:59 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:59 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.480 seconds, with status 200
2016-06-17 13:18:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/118>
{'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
2016-06-17 13:18:59 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:59 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:59 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:18:59 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:18:59 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.502 seconds, with status 200
2016-06-17 13:18:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5>
{'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
2016-06-17 13:18:59 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:18:59 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:18:59 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:00 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:00 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.483 seconds, with status 200
2016-06-17 13:19:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/19903>
{'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
2016-06-17 13:19:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:19:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:19:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:19:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:19:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:19:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:19:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:19:00 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:00 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:00 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:01 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:01 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.776 seconds, with status 200
2016-06-17 13:19:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/96928>
{'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
2016-06-17 13:19:01 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:01 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:01 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:01 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:01 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.533 seconds, with status 200
2016-06-17 13:19:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1127>
{'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341862',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
2016-06-17 13:19:01 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:01 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:01 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:02 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:02 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.665 seconds, with status 200
2016-06-17 13:19:02 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/329>
{'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321001',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
2016-06-17 13:19:02 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:02 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:02 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:03 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 150
2016-06-17 13:19:03 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 1.050 seconds, with status 200
2016-06-17 13:19:03 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/55358>
{'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
2016-06-17 13:19:03 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:03 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:03 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.588 seconds, with status 200
2016-06-17 13:19:04 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/346>
{'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
2016-06-17 13:19:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:04 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:04 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.515 seconds, with status 200
2016-06-17 13:19:04 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1363>
{'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29797',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
2016-06-17 13:19:04 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:04 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:04 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:05 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.483 seconds, with status 200
2016-06-17 13:19:05 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/109>
{'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
2016-06-17 13:19:05 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:05 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:05 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.584 seconds, with status 200
2016-06-17 13:19:05 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1357>
{'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
2016-06-17 13:19:05 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:05 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:06 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.638 seconds, with status 200
2016-06-17 13:19:06 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/270422>
{'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
2016-06-17 13:19:06 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:06 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:06 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.492 seconds, with status 200
2016-06-17 13:19:06 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1110>
{'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
2016-06-17 13:19:06 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:06 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:07 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.671 seconds, with status 200
2016-06-17 13:19:07 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/98>
{'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
2016-06-17 13:19:07 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:07 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:08 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.517 seconds, with status 200
2016-06-17 13:19:08 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/332>
{'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
2016-06-17 13:19:08 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:08 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:09 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 150
2016-06-17 13:19:09 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 1.199 seconds, with status 200
2016-06-17 13:19:09 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71936>
{'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
2016-06-17 13:19:09 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:09 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:09 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:09 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:09 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.506 seconds, with status 200
2016-06-17 13:19:09 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/108048>
{'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
2016-06-17 13:19:09 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:19:09 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:19:09 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:19:10 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:19:10 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.557 seconds, with status 200
2016-06-17 13:19:10 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1045>
{'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
2016-06-17 13:19:10 [scrapy] INFO: Closing spider (finished)
2016-06-17 13:19:10 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324121,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 20, 19, 10, 360252),
 'item_scraped_count': 48,
 'log_count/DEBUG': 292,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 20, 18, 38, 473302)}
2016-06-17 13:19:10 [scrapy] INFO: Spider closed (finished)
2016-06-17 13:20:02 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 13:20:02 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 13:20:02 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 13:20:02 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 13:20:02 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 13:20:02 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 13:20:02 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 13:20:02 [scrapy] INFO: Spider opened
2016-06-17 13:20:02 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 13:20:02 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 13:20:03 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 13:20:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 13:20:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221045%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221045%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221045%22&wt=json' (get) with body '' in 0.024 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%227055%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%227055%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%227055%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2239086%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2239086%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2239086%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221023%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221023%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221023%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253978',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1984', u'69660', u'330724', u'360'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221122%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221122%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221122%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121772',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225314%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%225314%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225314%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22125%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22125%22&wt=json HTTP/1.1" 400 281
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22125%22&wt=json' (get) with body '' in 0.007 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224928%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%224928%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224928%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221359%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221359%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221359%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%222094%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%222094%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%222094%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221131%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221131%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221131%22&wt=json' (get) with body '' in 0.007 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22497%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22497%22&wt=json HTTP/1.1" 400 281
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22497%22&wt=json' (get) with body '' in 0.008 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221326%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221326%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221326%22&wt=json' (get) with body '' in 0.007 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22219%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22219%22&wt=json HTTP/1.1" 400 281
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22219%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2219903%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2219903%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2219903%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%225%22&wt=json HTTP/1.1" 400 279
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2296928%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2296928%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2296928%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2254719%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2254719%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2254719%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224888%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%224888%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224888%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22297%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22297%22&wt=json HTTP/1.1" 400 281
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22297%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2213900%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2213900%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2213900%22&wt=json' (get) with body '' in 0.007 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%228543%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%228543%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%228543%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221109%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221109%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221109%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2229837%22&wt=json' (get) with body ''...
2016-06-17 13:20:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2229837%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2229837%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:05 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2258634%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2258634%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2258634%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22374173%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22374173%22&wt=json HTTP/1.1" 400 284
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22374173%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22323%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22323%22&wt=json HTTP/1.1" 400 281
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22323%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221338%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221338%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221338%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24332',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2231322%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2231322%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2231322%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2222704%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2222704%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2222704%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2210411%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2210411%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2210411%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22118%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22118%22&wt=json HTTP/1.1" 400 281
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22118%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22419543%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22419543%22&wt=json HTTP/1.1" 400 284
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22419543%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%229744%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%229744%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%229744%22&wt=json' (get) with body '' in 0.007 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221127%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221127%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221127%22&wt=json' (get) with body '' in 0.007 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341862',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221294%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221294%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221294%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22329%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22329%22&wt=json HTTP/1.1" 400 281
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22329%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321001',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2255358%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2255358%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2255358%22&wt=json' (get) with body '' in 0.008 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22346%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22346%22&wt=json HTTP/1.1" 400 281
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22346%22&wt=json' (get) with body '' in 0.007 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221363%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221363%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221363%22&wt=json' (get) with body '' in 0.007 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29797',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22109%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22109%22&wt=json HTTP/1.1" 400 281
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22109%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22270422%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22270422%22&wt=json HTTP/1.1" 400 284
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22270422%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221357%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221357%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221357%22&wt=json' (get) with body '' in 0.012 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221110%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221110%22&wt=json HTTP/1.1" 400 282
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221110%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1984', u'69660', u'330724', u'360'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2298%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2298%22&wt=json HTTP/1.1" 400 280
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2298%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22332%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22332%22&wt=json HTTP/1.1" 400 281
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22332%22&wt=json' (get) with body '' in 0.006 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2271936%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2271936%22&wt=json HTTP/1.1" 400 283
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2271936%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:20:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22108048%22&wt=json' (get) with body ''...
2016-06-17 13:20:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22108048%22&wt=json HTTP/1.1" 400 284
2016-06-17 13:20:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22108048%22&wt=json' (get) with body '' in 0.005 seconds, with status 400
2016-06-17 13:20:06 [pysolr] ERROR: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 101, in process_item
    result = self.solr.search(query)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 710, in search
    response = self._select(params, handler=search_handler)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 411, in _select
    return self._send_request('get', path)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pysolr.py", line 386, in _send_request
    raise SolrError(error_message % (resp.status_code, solr_message))
SolrError: Solr responded with an error (HTTP 400): [Reason: undefined field appid]
2016-06-17 13:20:06 [scrapy] INFO: Closing spider (finished)
2016-06-17 13:20:06 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324269,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 20, 20, 6, 663645),
 'log_count/DEBUG': 148,
 'log_count/ERROR': 96,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 20, 20, 2, 850228)}
2016-06-17 13:20:06 [scrapy] INFO: Spider closed (finished)
2016-06-17 13:27:11 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 13:27:11 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 13:27:11 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 13:27:11 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 13:27:11 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 13:27:11 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 13:27:11 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 13:27:11 [scrapy] INFO: Spider opened
2016-06-17 13:27:11 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 13:27:11 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 13:27:12 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 13:27:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 13:27:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:13 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:13 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:13 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 13:27:13 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.745 seconds, with status 200
2016-06-17 13:27:13 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1110>
{'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
2016-06-17 13:27:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:13 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:14 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:14 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:14 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:14 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:14 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.547 seconds, with status 200
2016-06-17 13:27:14 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/108048>
{'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
2016-06-17 13:27:14 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:14 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:14 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:14 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:14 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:14 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:14 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:14 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:14 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:14 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:14 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:15 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:15 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.876 seconds, with status 200
2016-06-17 13:27:15 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/98>
{'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
2016-06-17 13:27:15 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:15 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:15 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.608 seconds, with status 200
2016-06-17 13:27:16 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1359>
{'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
2016-06-17 13:27:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.497 seconds, with status 200
2016-06-17 13:27:16 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/332>
{'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
2016-06-17 13:27:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 150
2016-06-17 13:27:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 1.016 seconds, with status 200
2016-06-17 13:27:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1045>
{'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
2016-06-17 13:27:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:18 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:18 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.513 seconds, with status 200
2016-06-17 13:27:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5314>
{'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
2016-06-17 13:27:18 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:18 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:18 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:18 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:18 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.499 seconds, with status 200
2016-06-17 13:27:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71936>
{'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
2016-06-17 13:27:18 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:18 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:18 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:19 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:19 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.547 seconds, with status 200
2016-06-17 13:27:19 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/39086>
{'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
2016-06-17 13:27:19 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:19 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:19 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:19 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:19 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:19 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:19 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:19 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:19 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:19 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:19 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:19 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:19 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.548 seconds, with status 200
2016-06-17 13:27:19 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1122>
{'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121772',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
2016-06-17 13:27:19 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:19 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:19 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:20 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:20 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.531 seconds, with status 200
2016-06-17 13:27:20 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1023>
{'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253978',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
2016-06-17 13:27:20 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:20 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:20 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:20 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:20 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.556 seconds, with status 200
2016-06-17 13:27:20 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/7055>
{'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
2016-06-17 13:27:20 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:20 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:20 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.637 seconds, with status 200
2016-06-17 13:27:21 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4928>
{'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
2016-06-17 13:27:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.618 seconds, with status 200
2016-06-17 13:27:22 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/219>
{'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
2016-06-17 13:27:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:23 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:23 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.965 seconds, with status 200
2016-06-17 13:27:23 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/125>
{'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
2016-06-17 13:27:23 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:23 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:23 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:23 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:23 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.489 seconds, with status 200
2016-06-17 13:27:23 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1109>
{'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
2016-06-17 13:27:23 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:23 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:23 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:24 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:24 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.541 seconds, with status 200
2016-06-17 13:27:24 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/13900>
{'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
2016-06-17 13:27:24 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:24 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:24 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:24 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:24 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:24 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:24 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:24 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:24 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:24 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:24 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:24 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:24 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.515 seconds, with status 200
2016-06-17 13:27:24 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4888>
{'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
2016-06-17 13:27:24 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:24 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:24 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:25 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:25 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.480 seconds, with status 200
2016-06-17 13:27:25 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/297>
{'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
2016-06-17 13:27:25 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:25 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:25 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:25 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:25 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.532 seconds, with status 200
2016-06-17 13:27:25 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/54719>
{'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
2016-06-17 13:27:25 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:25 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:25 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:26 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:26 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.633 seconds, with status 200
2016-06-17 13:27:26 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/8543>
{'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
2016-06-17 13:27:26 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:26 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:26 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:26 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:26 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.539 seconds, with status 200
2016-06-17 13:27:26 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29837>
{'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
2016-06-17 13:27:26 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:26 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:26 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:27 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:27 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.606 seconds, with status 200
2016-06-17 13:27:27 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/58634>
{'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
2016-06-17 13:27:27 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:27 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:27 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:28 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:28 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.952 seconds, with status 200
2016-06-17 13:27:28 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/31322>
{'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
2016-06-17 13:27:28 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:28 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:28 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:29 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:29 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.536 seconds, with status 200
2016-06-17 13:27:29 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1338>
{'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24332',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
2016-06-17 13:27:29 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:29 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:29 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:29 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:29 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:29 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:29 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:29 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:29 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:29 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:29 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:29 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:29 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.544 seconds, with status 200
2016-06-17 13:27:29 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/323>
{'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
2016-06-17 13:27:29 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:29 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:29 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:30 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:30 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.696 seconds, with status 200
2016-06-17 13:27:30 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/374173>
{'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
2016-06-17 13:27:30 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:30 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:30 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:30 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:30 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.499 seconds, with status 200
2016-06-17 13:27:30 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/22704>
{'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
2016-06-17 13:27:30 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:30 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:30 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:31 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:31 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.584 seconds, with status 200
2016-06-17 13:27:31 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/118>
{'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
2016-06-17 13:27:31 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:31 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:31 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:31 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:31 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.573 seconds, with status 200
2016-06-17 13:27:31 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/10411>
{'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
2016-06-17 13:27:31 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:31 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:31 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:32 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:32 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.623 seconds, with status 200
2016-06-17 13:27:32 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/419543>
{'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
2016-06-17 13:27:32 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:32 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:32 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.538 seconds, with status 200
2016-06-17 13:27:33 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/9744>
{'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
2016-06-17 13:27:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 150
2016-06-17 13:27:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 1.008 seconds, with status 200
2016-06-17 13:27:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1294>
{'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
2016-06-17 13:27:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:34 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:27:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.554 seconds, with status 200
2016-06-17 13:27:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1131>
{'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
2016-06-17 13:27:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:35 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:35 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.648 seconds, with status 200
2016-06-17 13:27:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/2094>
{'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
2016-06-17 13:27:35 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:35 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:35 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:35 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:35 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.526 seconds, with status 200
2016-06-17 13:27:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/497>
{'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
2016-06-17 13:27:35 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:35 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:35 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:36 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:36 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.572 seconds, with status 200
2016-06-17 13:27:36 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1326>
{'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
2016-06-17 13:27:36 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:36 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:36 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:37 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:37 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.830 seconds, with status 200
2016-06-17 13:27:37 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5>
{'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
2016-06-17 13:27:37 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:37 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:37 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:37 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:37 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.517 seconds, with status 200
2016-06-17 13:27:37 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/19903>
{'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
2016-06-17 13:27:37 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:37 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:37 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:38 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:38 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.502 seconds, with status 200
2016-06-17 13:27:38 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/96928>
{'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
2016-06-17 13:27:38 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:38 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:38 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:38 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:38 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.565 seconds, with status 200
2016-06-17 13:27:38 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1127>
{'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341862',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
2016-06-17 13:27:38 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:38 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:38 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 150
2016-06-17 13:27:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 1.055 seconds, with status 200
2016-06-17 13:27:40 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/329>
{'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321002',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
2016-06-17 13:27:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:40 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:40 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.506 seconds, with status 200
2016-06-17 13:27:40 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/55358>
{'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
2016-06-17 13:27:40 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:40 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:40 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.480 seconds, with status 200
2016-06-17 13:27:41 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/346>
{'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
2016-06-17 13:27:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:41 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:41 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.549 seconds, with status 200
2016-06-17 13:27:41 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1363>
{'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29797',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
2016-06-17 13:27:41 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:41 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:41 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:42 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:42 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.665 seconds, with status 200
2016-06-17 13:27:42 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/109>
{'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
2016-06-17 13:27:42 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:42 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:42 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:42 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:42 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.506 seconds, with status 200
2016-06-17 13:27:42 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1357>
{'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
2016-06-17 13:27:42 [pysolr] DEBUG: Starting to build add request...
2016-06-17 13:27:42 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 13:27:42 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 13:27:43 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 13:27:43 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.540 seconds, with status 200
2016-06-17 13:27:43 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/270422>
{'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
2016-06-17 13:27:43 [scrapy] INFO: Closing spider (finished)
2016-06-17 13:27:43 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324121,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 20, 27, 43, 323338),
 'item_scraped_count': 48,
 'log_count/DEBUG': 292,
 'log_count/INFO': 56,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 20, 27, 11, 453767)}
2016-06-17 13:27:43 [scrapy] INFO: Spider closed (finished)
2016-06-17 13:28:46 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 13:28:46 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 13:28:46 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 13:28:46 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 13:28:46 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 13:28:46 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 13:28:46 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 13:28:46 [scrapy] INFO: Spider opened
2016-06-17 13:28:46 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 13:28:46 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 13:28:47 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 13:28:47 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 13:28:47 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2255358%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2255358%22&wt=json HTTP/1.1" 200 558
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2255358%22&wt=json' (get) with body '' in 0.025 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/55358>
{'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221363%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221363%22&wt=json HTTP/1.1" 200 456
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221363%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1363>
{'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29797',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22346%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22346%22&wt=json HTTP/1.1" 200 516
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22346%22&wt=json' (get) with body '' in 0.008 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/346>
{'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22109%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22109%22&wt=json HTTP/1.1" 200 550
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22109%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/109>
{'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22332%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22332%22&wt=json HTTP/1.1" 200 489
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22332%22&wt=json' (get) with body '' in 0.008 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/332>
{'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221357%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221357%22&wt=json HTTP/1.1" 200 570
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221357%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1357>
{'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22270422%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22270422%22&wt=json HTTP/1.1" 200 431
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22270422%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/270422>
{'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221110%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221110%22&wt=json HTTP/1.1" 200 502
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221110%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1110>
{'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1984', u'69660', u'330724', u'360'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2298%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2298%22&wt=json HTTP/1.1" 200 531
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2298%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/98>
{'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2271936%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2271936%22&wt=json HTTP/1.1" 200 553
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2271936%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71936>
{'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2239086%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2239086%22&wt=json HTTP/1.1" 200 555
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2239086%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/39086>
{'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225314%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%225314%22&wt=json HTTP/1.1" 200 555
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225314%22&wt=json' (get) with body '' in 0.009 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5314>
{'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221122%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221122%22&wt=json HTTP/1.1" 200 553
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221122%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1122>
{'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121772',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221359%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221359%22&wt=json HTTP/1.1" 200 546
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221359%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1359>
{'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22219%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22219%22&wt=json HTTP/1.1" 200 449
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22219%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/219>
{'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22108048%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22108048%22&wt=json HTTP/1.1" 200 516
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22108048%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/108048>
{'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221045%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221045%22&wt=json HTTP/1.1" 200 557
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221045%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1045>
{'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219839',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2254719%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2254719%22&wt=json HTTP/1.1" 200 522
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2254719%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/54719>
{'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22297%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22297%22&wt=json HTTP/1.1" 200 552
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22297%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/297>
{'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224888%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%224888%22&wt=json HTTP/1.1" 200 542
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224888%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4888>
{'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221109%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221109%22&wt=json HTTP/1.1" 200 542
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221109%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1109>
{'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2213900%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2213900%22&wt=json HTTP/1.1" 200 545
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2213900%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/13900>
{'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
2016-06-17 13:28:48 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%228543%22&wt=json' (get) with body ''...
2016-06-17 13:28:48 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%228543%22&wt=json HTTP/1.1" 200 533
2016-06-17 13:28:48 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%228543%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:48 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:48 [root] INFO: Skip duplicates
2016-06-17 13:28:48 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/8543>
{'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:48 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2229837%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2229837%22&wt=json HTTP/1.1" 200 563
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2229837%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29837>
{'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2258634%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2258634%22&wt=json HTTP/1.1" 200 513
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2258634%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/58634>
{'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2231322%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2231322%22&wt=json HTTP/1.1" 200 532
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2231322%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/31322>
{'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221338%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221338%22&wt=json HTTP/1.1" 200 543
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221338%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1338>
{'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24332',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22323%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22323%22&wt=json HTTP/1.1" 200 518
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22323%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/323>
{'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22374173%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22374173%22&wt=json HTTP/1.1" 200 526
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22374173%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/374173>
{'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2222704%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2222704%22&wt=json HTTP/1.1" 200 551
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2222704%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/22704>
{'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22118%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22118%22&wt=json HTTP/1.1" 200 536
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22118%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/118>
{'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'378879', u'1100', u'98666'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22419543%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22419543%22&wt=json HTTP/1.1" 200 451
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22419543%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/419543>
{'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2210411%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2210411%22&wt=json HTTP/1.1" 200 538
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2210411%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/10411>
{'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%229744%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%229744%22&wt=json HTTP/1.1" 200 553
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%229744%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/9744>
{'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%222094%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%222094%22&wt=json HTTP/1.1" 200 539
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%222094%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/2094>
{'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221294%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221294%22&wt=json HTTP/1.1" 200 574
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221294%22&wt=json' (get) with body '' in 0.009 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1294>
{'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221131%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221131%22&wt=json HTTP/1.1" 200 544
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221131%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1131>
{'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22497%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22497%22&wt=json HTTP/1.1" 200 542
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22497%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/497>
{'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2219903%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2219903%22&wt=json HTTP/1.1" 200 566
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2219903%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/19903>
{'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221326%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221326%22&wt=json HTTP/1.1" 200 554
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221326%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1326>
{'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%225%22&wt=json HTTP/1.1" 200 538
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5>
{'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2296928%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2296928%22&wt=json HTTP/1.1" 200 476
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2296928%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/96928>
{'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22329%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22329%22&wt=json HTTP/1.1" 200 497
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22329%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/329>
{'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321002',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221127%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221127%22&wt=json HTTP/1.1" 200 547
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221127%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1127>
{'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341862',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221023%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221023%22&wt=json HTTP/1.1" 200 546
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221023%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1023>
{'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253978',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22125%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22125%22&wt=json HTTP/1.1" 200 544
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22125%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/125>
{'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%227055%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%227055%22&wt=json HTTP/1.1" 200 564
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%227055%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/7055>
{'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
2016-06-17 13:28:49 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224928%22&wt=json' (get) with body ''...
2016-06-17 13:28:49 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%224928%22&wt=json HTTP/1.1" 200 536
2016-06-17 13:28:49 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224928%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 13:28:49 [pysolr] DEBUG: Found '1' search results.
2016-06-17 13:28:49 [root] INFO: Skip duplicates
2016-06-17 13:28:49 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4928>
{'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
2016-06-17 13:28:49 [scrapy] INFO: Closing spider (finished)
2016-06-17 13:28:49 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324290,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 20, 28, 49, 788984),
 'item_scraped_count': 48,
 'log_count/DEBUG': 244,
 'log_count/INFO': 104,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 20, 28, 46, 416658)}
2016-06-17 13:28:49 [scrapy] INFO: Spider closed (finished)
2016-06-17 13:39:52 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 13:39:52 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 13:39:52 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 13:39:52 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 13:39:52 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 13:39:52 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 13:39:52 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiElasticSearchPipeline',
 'xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 13:39:52 [scrapy] INFO: Spider opened
2016-06-17 13:39:52 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 13:39:52 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 13:39:53 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 13:39:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 13:39:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/19903?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/19903?op_type=create [status:409 request:0.003s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-06-15", "version": "5.8.7", "title": "", "count": "17981", "related_recommended": ["55690", "58894", "28090", "1254"], "developer_recommended": ["96822", "31243", "55690", "392543"], "appid": "19903", "groupid": "3", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][19903]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][19903]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][19903]: document already exists')
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1127?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/1127?op_type=create [status:409 request:0.002s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-17", "version": "6.6.1", "title": "", "count": "341863", "related_recommended": ["34507", "16938", "58458", "323"], "developer_recommended": ["379843", "283", "97015"], "appid": "1127", "groupid": "2", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1127]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1127]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341863',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1127]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/96928?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/96928?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-04-22", "version": "4.0.2", "title": "", "count": "9743", "related_recommended": ["23418", "99376", "72342", "89462"], "developer_recommended": [], "appid": "96928", "groupid": "23", "developer": "superpop"}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][96928]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][96928]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][96928]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1363?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/1363?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "7", "update_time": "2016-06-15", "version": "10.10.3.810", "title": "UC", "count": "29797", "related_recommended": [], "developer_recommended": [], "appid": "1363", "groupid": "5", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1363]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1363]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29797',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1363]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/329?op_type=create HTTP/1.1" 409 283
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/329?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-05-26", "version": "4.45.0.1504", "title": "", "count": "321002", "related_recommended": ["2027", "91399", "26484", "63932"], "developer_recommended": [], "appid": "329", "groupid": "6", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][329]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][329]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321002',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][329]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/346?op_type=create HTTP/1.1" 409 283
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/346?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-06", "version": "6.9.2", "title": "", "count": "22539", "related_recommended": ["129", "19174", "68656", "61518"], "developer_recommended": ["319980"], "appid": "346", "groupid": "2", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][346]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][346]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][346]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/109?op_type=create HTTP/1.1" 409 283
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/109?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-08", "version": "8.1.2", "title": "", "count": "74989", "related_recommended": ["31233", "11659", "31250", "1131"], "developer_recommended": ["45243", "50634", "44900", "31233"], "appid": "109", "groupid": "27", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][109]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][109]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][109]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1357?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/1357?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-06-02", "version": "4.8.5.10223", "title": "", "count": "18203", "related_recommended": ["181", "2889", "3581", "897"], "developer_recommended": ["39312", "2241", "100053", "7012"], "appid": "1357", "groupid": "27", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1357]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1357]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1357]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/55358?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/55358?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-05-03", "version": "4.5.1", "title": "", "count": "2442", "related_recommended": ["1076", "25855", "33749", "20649"], "developer_recommended": ["419901", "100053", "184154", "289530"], "appid": "55358", "groupid": "2", "developer": ")"}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][55358]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][55358]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][55358]: document already exists')
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/270422?op_type=create HTTP/1.1" 409 289
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/270422?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "7", "update_time": "2016-06-08", "version": "1.1.18", "title": "", "count": "465", "related_recommended": [], "developer_recommended": [], "appid": "270422", "groupid": "27", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][270422]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][270422]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][270422]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1110?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/1110?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "7", "update_time": "2016-06-02", "version": "9.6.8.053103", "title": "", "count": "37029", "related_recommended": [], "developer_recommended": ["59991", "53514"], "appid": "1110", "groupid": "1", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1110]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1110]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1110]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/98?op_type=create HTTP/1.1" 409 281
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/98?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-06-02", "version": "6.9.2", "title": "", "count": "9055", "related_recommended": ["55992", "56249", "1141", "1046"], "developer_recommended": ["103794", "9037", "55992", "103515"], "appid": "98", "groupid": "9", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][98]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][98]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][98]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/332?op_type=create HTTP/1.1" 409 283
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/332?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-05-17", "version": "5.1.0", "title": "", "count": "2648", "related_recommended": ["69662", "58628", "33976", "9531"], "developer_recommended": [], "appid": "332", "groupid": "9", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][332]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][332]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][332]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/108048?op_type=create HTTP/1.1" 409 289
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/108048?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "RPG", "rating": "7", "update_time": "2016-05-13", "version": "1.12.1.7", "title": "", "count": "26282", "related_recommended": [], "developer_recommended": ["419901", "100053", "184154", "289530"], "appid": "108048", "groupid": "19", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][108048]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][108048]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][108048]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/71936?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/71936?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-13", "version": "3.5.8.278", "title": "K", "count": "4178", "related_recommended": ["72149", "84504", "54227", "26484"], "developer_recommended": ["419901", "96199", "57492", "235034"], "appid": "71936", "groupid": "27", "developer": ")"}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][71936]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][71936]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][71936]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/219?op_type=create HTTP/1.1" 409 283
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/219?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-06-06", "version": "9.3.1", "title": "", "count": "17386", "related_recommended": [], "developer_recommended": [], "appid": "219", "groupid": "3", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][219]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][219]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][219]: document already exists')
2016-06-17 13:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:54 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1045?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:54 [elasticsearch] WARNING: PUT /scrapy/items/1045?op_type=create [status:409 request:0.002s]
2016-06-17 13:39:54 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-07", "version": "5.7", "title": "", "count": "219842", "related_recommended": ["2095", "50508", "69754", "51833"], "developer_recommended": ["394794", "325526", "187579", "57429"], "appid": "1045", "groupid": "27", "developer": ""}
2016-06-17 13:39:54 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1045]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1045]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:54 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219842',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1045]: document already exists')
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/4888?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/4888?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "4", "update_time": "2016-05-26", "version": "5.19.1", "title": "", "count": "2168", "related_recommended": ["15228", "99959", "9531", "11597"], "developer_recommended": ["75339", "113506", "1984", "69660"], "appid": "4888", "groupid": "9", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][4888]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][4888]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][4888]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/297?op_type=create HTTP/1.1" 409 283
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/297?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "4", "update_time": "2016-06-13", "version": "6.7.2.2445", "title": "QQ", "count": "6522", "related_recommended": ["321", "62787", "37993", "5966"], "developer_recommended": ["5007", "116315", "8253", "45173"], "appid": "297", "groupid": "5", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][297]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][297]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][297]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/54719?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/54719?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-16", "version": "6.1.0", "title": "-", "count": "231244", "related_recommended": ["75060", "49915", "48473", "73537"], "developer_recommended": [], "appid": "54719", "groupid": "12", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][54719]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][54719]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][54719]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1109?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/1109?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-15", "version": "5.5.2", "title": "YY", "count": "69583", "related_recommended": ["62957", "59208", "86608", "35295"], "developer_recommended": ["51833", "276471", "361787", "209755"], "appid": "1109", "groupid": "2", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1109]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1109]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1109]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/8543?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/8543?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-13", "version": "3.107.1", "title": " - Uber", "count": "7439", "related_recommended": ["11150", "10411", "4958", "34162"], "developer_recommended": ["245241"], "appid": "8543", "groupid": "3", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][8543]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][8543]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][8543]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/13900?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/13900?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-03-01", "version": "6.0.3", "title": "", "count": "3922", "related_recommended": ["49723", "43332", "2889", "63267"], "developer_recommended": ["69474", "71279", "266237", "43332"], "appid": "13900", "groupid": "27", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][13900]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][13900]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][13900]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/29837?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/29837?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-05-30", "version": "6.7.2", "title": "QQ", "count": "28006", "related_recommended": ["21976", "68657", "27650", "62091"], "developer_recommended": ["419901", "100053", "184154", "289530"], "appid": "29837", "groupid": "5", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][29837]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][29837]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][29837]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/58634?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/58634?op_type=create [status:409 request:0.002s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-05-23", "version": "1.33", "title": "", "count": "123444", "related_recommended": [], "developer_recommended": ["70764", "72358", "64325", "52411"], "appid": "58634", "groupid": "23", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][58634]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][58634]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][58634]: document already exists')
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/31322?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/31322?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "4", "update_time": "2016-06-17", "version": "5.8.4", "title": "", "count": "11027", "related_recommended": ["1294", "897", "125", "1357"], "developer_recommended": ["394794"], "appid": "31322", "groupid": "27", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][31322]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][31322]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][31322]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1338?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/1338?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-05-25", "version": "7.7.0.0.2036", "title": "", "count": "24332", "related_recommended": ["32323", "46455", "4959", "405"], "developer_recommended": ["114080", "93699", "46455", "201840"], "appid": "1338", "groupid": "3", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1338]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1338]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24332',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1338]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/323?op_type=create HTTP/1.1" 409 283
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/323?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-05-13", "version": "7.4.66", "title": "", "count": "3446", "related_recommended": ["1008", "99959", "1127", "32323"], "developer_recommended": ["68548", "121089", "153601", "200058"], "appid": "323", "groupid": "2", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][323]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][323]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][323]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/374173?op_type=create HTTP/1.1" 409 289
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/374173?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-06-08", "version": "1.3.1", "title": "", "count": "1346", "related_recommended": [], "developer_recommended": ["117302", "80542", "311330", "257019"], "appid": "374173", "groupid": "17", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][374173]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][374173]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][374173]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/22704?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/22704?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-17", "version": "7.0.6.1", "title": "58", "count": "22269", "related_recommended": ["69736", "61175", "3726", "99959"], "developer_recommended": ["257650", "117457", "61175", "105478"], "appid": "22704", "groupid": "4", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][22704]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][22704]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][22704]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/10411?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/10411?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-16", "version": "4.3.8", "title": "", "count": "7681", "related_recommended": ["4958", "34162", "79713", "81823"], "developer_recommended": ["8914", "103203", "146850"], "appid": "10411", "groupid": "3", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][10411]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][10411]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][10411]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/419543?op_type=create HTTP/1.1" 409 289
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/419543?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "RPG", "rating": "6", "update_time": "2016-06-16", "version": "1.3.1", "title": "", "count": "101", "related_recommended": [], "developer_recommended": [], "appid": "419543", "groupid": "19", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][419543]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][419543]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][419543]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/118?op_type=create HTTP/1.1" 409 283
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/118?op_type=create [status:409 request:0.003s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-05-31", "version": "5.5.0", "title": "PPS", "count": "17806", "related_recommended": ["125", "155", "310", "1121"], "developer_recommended": ["192", "50219", "402506", "9519"], "appid": "118", "groupid": "27", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][118]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][118]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][118]: document already exists')
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/9744?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/9744?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "3", "update_time": "2016-05-28", "version": "5.17.2.4000", "title": "", "count": "10661", "related_recommended": ["44238", "310", "56059", "1098"], "developer_recommended": ["414306", "329235", "89937", "115378"], "appid": "9744", "groupid": "27", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][9744]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][9744]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][9744]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/2094?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/2094?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-16", "version": "4.20.0", "title": "", "count": "14661", "related_recommended": ["29919", "56059", "8752", "72389"], "developer_recommended": ["381359"], "appid": "2094", "groupid": "27", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][2094]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][2094]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][2094]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1131?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/1131?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-06-07", "version": "6.1.1.10", "title": "QQ", "count": "49043", "related_recommended": ["11659", "31250", "7", "301"], "developer_recommended": ["419901", "96199", "71936", "57492"], "appid": "1131", "groupid": "27", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1131]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1131]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1131]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1294?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/1294?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "7", "update_time": "2016-05-19", "version": "6.6.1", "title": "-", "count": "35080", "related_recommended": ["50508", "2889", "3581", "125"], "developer_recommended": ["369096", "113128", "45617", "378877"], "appid": "1294", "groupid": "27", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1294]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1294]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1294]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/497?op_type=create HTTP/1.1" 409 283
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/497?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "10", "update_time": "2016-06-14", "version": "6.6.2", "title": "-6", "count": "93056", "related_recommended": ["73695", "2133", "1300", "39588"], "developer_recommended": ["73695", "78008"], "appid": "497", "groupid": "9", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][497]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][497]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][497]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1326?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/1326?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "10", "update_time": "2016-06-16", "version": "5.1.0.0", "title": "", "count": "147989", "related_recommended": ["1057", "81532", "33695", "85051"], "developer_recommended": ["63447", "110320", "293149", "24269"], "appid": "1326", "groupid": "6", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1326]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1326]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1326]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/39086?op_type=create HTTP/1.1" 409 287
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/39086?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "4", "update_time": "2016-05-26", "version": "4.6.9", "title": "TV", "count": "10987", "related_recommended": ["47269", "69754", "1132", "16590"], "developer_recommended": ["405228", "156423", "73276"], "appid": "39086", "groupid": "27", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][39086]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][39086]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][39086]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/5?op_type=create HTTP/1.1" 409 279
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/5?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "7", "update_time": "2016-06-07", "version": "8.0.6.1363", "title": "", "count": "6882", "related_recommended": ["81816", "228", "16590", "50989"], "developer_recommended": ["326345", "81816", "88478", "110188"], "appid": "5", "groupid": "9", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][5]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][5]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][5]: document already exists')
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1122?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/1122?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-06", "version": "6.3.18", "title": "", "count": "121772", "related_recommended": ["52029", "297", "1359", "82846"], "developer_recommended": ["419901", "96199", "297", "39312"], "appid": "1122", "groupid": "2", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1122]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1122]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121772',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1122]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1359?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/1359?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-05-27", "version": "6.3.7", "title": "QQ", "count": "133577", "related_recommended": ["58458", "1109", "315", "7464"], "developer_recommended": ["419901", "100053", "184154", "289530"], "appid": "1359", "groupid": "2", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1359]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1359]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1359]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/5314?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/5314?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-07", "version": "7.13.0", "title": "", "count": "12640", "related_recommended": ["82805", "57257", "5930", "57983"], "developer_recommended": ["321", "10025", "192", "378879"], "appid": "5314", "groupid": "5", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][5314]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][5314]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][5314]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1023?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/1023?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "10", "update_time": "2016-06-02", "version": "5.8.0", "title": "", "count": "253978", "related_recommended": ["16116", "2086", "452", "307"], "developer_recommended": ["75339", "113506", "1984", "69660"], "appid": "1023", "groupid": "9", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1023]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1023]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253978',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1023]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/125?op_type=create HTTP/1.1" 409 283
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/125?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-06-02", "version": "7.5.1", "title": "-4", "count": "54001", "related_recommended": ["118", "39086", "2095", "155"], "developer_recommended": ["396378", "118", "97530", "22909"], "appid": "125", "groupid": "27", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][125]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][125]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][125]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/7055?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/7055?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-13", "version": "5.21.7", "title": "-", "count": "10175", "related_recommended": ["52475", "11597", "39120", "19873"], "developer_recommended": ["89001", "103342", "80107", "52475"], "appid": "7055", "groupid": "9", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][7055]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][7055]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][7055]: document already exists')
2016-06-17 13:39:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:39:55 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/4928?op_type=create HTTP/1.1" 409 285
2016-06-17 13:39:55 [elasticsearch] WARNING: PUT /scrapy/items/4928?op_type=create [status:409 request:0.001s]
2016-06-17 13:39:55 [elasticsearch] DEBUG: > {"category": "", "rating": "10", "update_time": "2016-06-12", "version": "5.1.0", "title": "", "count": "12099", "related_recommended": ["72617", "96743", "79984", "360"], "developer_recommended": ["80518", "59053", "11867"], "appid": "4928", "groupid": "9", "developer": ""}
2016-06-17 13:39:55 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][4928]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][4928]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:39:55 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][4928]: document already exists')
2016-06-17 13:39:55 [scrapy] INFO: Closing spider (finished)
2016-06-17 13:39:55 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324147,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 20, 39, 55, 955306),
 'log_count/DEBUG': 244,
 'log_count/ERROR': 48,
 'log_count/INFO': 8,
 'log_count/WARNING': 49,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 20, 39, 52, 680269)}
2016-06-17 13:39:55 [scrapy] INFO: Spider closed (finished)
2016-06-17 13:40:28 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 13:40:28 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 13:40:28 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 13:40:28 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 13:40:28 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 13:40:28 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 13:40:28 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiElasticSearchPipeline',
 'xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 13:40:28 [scrapy] INFO: Spider opened
2016-06-17 13:40:28 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 13:40:28 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 13:40:29 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 13:40:29 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 13:40:29 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1363?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/1363?op_type=create [status:409 request:0.002s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "7", "update_time": "2016-06-15", "version": "10.10.3.810", "title": "UC", "count": "29797", "related_recommended": [], "developer_recommended": [], "appid": "1363", "groupid": "5", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1363]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1363]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29797',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1363]: document already exists')
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/109?op_type=create HTTP/1.1" 409 283
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/109?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-08", "version": "8.1.2", "title": "", "count": "74989", "related_recommended": ["31233", "11659", "31250", "1131"], "developer_recommended": ["45243", "50634", "44900", "31233"], "appid": "109", "groupid": "27", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][109]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][109]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][109]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/270422?op_type=create HTTP/1.1" 409 289
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/270422?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "7", "update_time": "2016-06-08", "version": "1.1.18", "title": "", "count": "465", "related_recommended": [], "developer_recommended": [], "appid": "270422", "groupid": "27", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][270422]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][270422]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][270422]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/108048?op_type=create HTTP/1.1" 409 289
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/108048?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "RPG", "rating": "7", "update_time": "2016-05-13", "version": "1.12.1.7", "title": "", "count": "26282", "related_recommended": [], "developer_recommended": ["419901", "100053", "184154", "289530"], "appid": "108048", "groupid": "19", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][108048]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][108048]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][108048]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1110?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/1110?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "7", "update_time": "2016-06-02", "version": "9.6.8.053103", "title": "", "count": "37029", "related_recommended": [], "developer_recommended": ["59991", "53514"], "appid": "1110", "groupid": "1", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1110]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1110]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1110]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/98?op_type=create HTTP/1.1" 409 281
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/98?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-06-02", "version": "6.9.2", "title": "", "count": "9055", "related_recommended": ["55992", "56249", "1141", "1046"], "developer_recommended": ["103794", "9037", "55992", "103515"], "appid": "98", "groupid": "9", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][98]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][98]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][98]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/332?op_type=create HTTP/1.1" 409 283
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/332?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-05-17", "version": "5.1.0", "title": "", "count": "2648", "related_recommended": ["69662", "58628", "33976", "9531"], "developer_recommended": [], "appid": "332", "groupid": "9", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][332]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][332]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][332]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1357?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/1357?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-06-02", "version": "4.8.5.10223", "title": "", "count": "18203", "related_recommended": ["181", "2889", "3581", "897"], "developer_recommended": ["39312", "2241", "100053", "7012"], "appid": "1357", "groupid": "27", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1357]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1357]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1357]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/71936?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/71936?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-13", "version": "3.5.8.278", "title": "K", "count": "4178", "related_recommended": ["72149", "84504", "54227", "26484"], "developer_recommended": ["419901", "96199", "57492", "235034"], "appid": "71936", "groupid": "27", "developer": ")"}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][71936]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][71936]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][71936]: document already exists')
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1045?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/1045?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-07", "version": "5.7", "title": "", "count": "219842", "related_recommended": ["2095", "50508", "69754", "51833"], "developer_recommended": ["364690", "394794", "85039", "325526"], "appid": "1045", "groupid": "27", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1045]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1045]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219842',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'364690', u'394794', u'85039', u'325526'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1045]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/5314?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/5314?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-07", "version": "7.13.0", "title": "", "count": "12640", "related_recommended": ["82805", "57257", "5930", "57983"], "developer_recommended": ["321", "10025", "192", "378879"], "appid": "5314", "groupid": "5", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][5314]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][5314]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][5314]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1359?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/1359?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-05-27", "version": "6.3.7", "title": "QQ", "count": "133577", "related_recommended": ["58458", "1109", "315", "7464"], "developer_recommended": ["419901", "100053", "184154", "289530"], "appid": "1359", "groupid": "2", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1359]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1359]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1359]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1122?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/1122?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-06", "version": "6.3.18", "title": "", "count": "121772", "related_recommended": ["52029", "297", "1359", "82846"], "developer_recommended": ["419901", "96199", "297", "39312"], "appid": "1122", "groupid": "2", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1122]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1122]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121772',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1122]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1023?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/1023?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "10", "update_time": "2016-06-02", "version": "5.8.0", "title": "", "count": "253978", "related_recommended": ["16116", "2086", "452", "307"], "developer_recommended": ["75339", "113506", "1984", "69660"], "appid": "1023", "groupid": "9", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1023]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1023]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253978',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1023]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/39086?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/39086?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "4", "update_time": "2016-05-26", "version": "4.6.9", "title": "TV", "count": "10987", "related_recommended": ["47269", "69754", "1132", "16590"], "developer_recommended": ["405228", "156423", "73276"], "appid": "39086", "groupid": "27", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][39086]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][39086]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][39086]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/219?op_type=create HTTP/1.1" 409 283
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/219?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-06-06", "version": "9.3.1", "title": "", "count": "17386", "related_recommended": [], "developer_recommended": [], "appid": "219", "groupid": "3", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][219]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][219]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][219]: document already exists')
2016-06-17 13:40:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:30 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/125?op_type=create HTTP/1.1" 409 283
2016-06-17 13:40:30 [elasticsearch] WARNING: PUT /scrapy/items/125?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:30 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-06-02", "version": "7.5.1", "title": "-4", "count": "54001", "related_recommended": ["118", "39086", "2095", "155"], "developer_recommended": ["396378", "118", "97530", "22909"], "appid": "125", "groupid": "27", "developer": ""}
2016-06-17 13:40:30 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][125]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][125]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:40:30 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][125]: document already exists')
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/4888?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/4888?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "4", "update_time": "2016-05-26", "version": "5.19.1", "title": "", "count": "2168", "related_recommended": ["15228", "99959", "9531", "11597"], "developer_recommended": ["75339", "113506", "1984", "69660"], "appid": "4888", "groupid": "9", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][4888]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][4888]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][4888]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/297?op_type=create HTTP/1.1" 409 283
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/297?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "4", "update_time": "2016-06-13", "version": "6.7.2.2445", "title": "QQ", "count": "6522", "related_recommended": ["321", "62787", "37993", "5966"], "developer_recommended": ["5007", "116315", "8253", "45173"], "appid": "297", "groupid": "5", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][297]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][297]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][297]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/54719?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/54719?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-16", "version": "6.1.0", "title": "-", "count": "231244", "related_recommended": ["75060", "49915", "48473", "73537"], "developer_recommended": [], "appid": "54719", "groupid": "12", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][54719]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][54719]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][54719]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/13900?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/13900?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-03-01", "version": "6.0.3", "title": "", "count": "3922", "related_recommended": ["49723", "43332", "2889", "63267"], "developer_recommended": ["69474", "71279", "266237", "43332"], "appid": "13900", "groupid": "27", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][13900]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][13900]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][13900]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1109?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/1109?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-15", "version": "5.5.2", "title": "YY", "count": "69583", "related_recommended": ["62957", "59208", "86608", "35295"], "developer_recommended": ["51833", "276471", "361787", "209755"], "appid": "1109", "groupid": "2", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1109]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1109]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1109]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/8543?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/8543?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-13", "version": "3.107.1", "title": " - Uber", "count": "7439", "related_recommended": ["11150", "10411", "4958", "34162"], "developer_recommended": ["245241"], "appid": "8543", "groupid": "3", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][8543]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][8543]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][8543]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/29837?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/29837?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-05-30", "version": "6.7.2", "title": "QQ", "count": "28006", "related_recommended": ["21976", "68657", "27650", "62091"], "developer_recommended": ["419901", "100053", "184154", "289530"], "appid": "29837", "groupid": "5", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][29837]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][29837]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][29837]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/58634?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/58634?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-05-23", "version": "1.33", "title": "", "count": "123444", "related_recommended": [], "developer_recommended": ["70764", "72358", "64325", "52411"], "appid": "58634", "groupid": "23", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][58634]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][58634]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123444',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][58634]: document already exists')
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/374173?op_type=create HTTP/1.1" 409 289
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/374173?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-06-08", "version": "1.3.1", "title": "", "count": "1346", "related_recommended": [], "developer_recommended": ["117302", "80542", "311330", "257019"], "appid": "374173", "groupid": "17", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][374173]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][374173]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][374173]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/31322?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/31322?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "4", "update_time": "2016-06-17", "version": "5.8.4", "title": "", "count": "11027", "related_recommended": ["1294", "897", "125", "1357"], "developer_recommended": ["394794"], "appid": "31322", "groupid": "27", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][31322]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][31322]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11027',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][31322]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/323?op_type=create HTTP/1.1" 409 283
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/323?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-05-13", "version": "7.4.66", "title": "", "count": "3446", "related_recommended": ["1008", "99959", "1127", "32323"], "developer_recommended": ["68548", "121089", "153601", "200058"], "appid": "323", "groupid": "2", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][323]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][323]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][323]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/22704?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/22704?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-17", "version": "7.0.6.1", "title": "58", "count": "22269", "related_recommended": ["69736", "61175", "3726", "99959"], "developer_recommended": ["257650", "117457", "61175", "105478"], "appid": "22704", "groupid": "4", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][22704]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][22704]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][22704]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/419543?op_type=create HTTP/1.1" 409 289
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/419543?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "RPG", "rating": "6", "update_time": "2016-06-16", "version": "1.3.1", "title": "", "count": "101", "related_recommended": [], "developer_recommended": [], "appid": "419543", "groupid": "19", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][419543]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][419543]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][419543]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1338?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/1338?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-05-25", "version": "7.7.0.0.2036", "title": "", "count": "24332", "related_recommended": ["32323", "46455", "4959", "405"], "developer_recommended": ["114080", "93699", "46455", "201840"], "appid": "1338", "groupid": "3", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1338]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1338]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24332',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1338]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/10411?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/10411?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-16", "version": "4.3.8", "title": "", "count": "7681", "related_recommended": ["4958", "34162", "79713", "81823"], "developer_recommended": ["8914", "103203", "146850"], "appid": "10411", "groupid": "3", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][10411]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][10411]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][10411]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/118?op_type=create HTTP/1.1" 409 283
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/118?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-05-31", "version": "5.5.0", "title": "PPS", "count": "17806", "related_recommended": ["125", "155", "310", "1121"], "developer_recommended": ["192", "50219", "402506", "9519"], "appid": "118", "groupid": "27", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][118]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][118]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][118]: document already exists')
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/9744?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/9744?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "3", "update_time": "2016-05-28", "version": "5.17.2.4000", "title": "", "count": "10661", "related_recommended": ["44238", "310", "56059", "1098"], "developer_recommended": ["414306", "329235", "89937", "115378"], "appid": "9744", "groupid": "27", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][9744]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][9744]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][9744]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/497?op_type=create HTTP/1.1" 409 283
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/497?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "10", "update_time": "2016-06-14", "version": "6.6.2", "title": "-6", "count": "93056", "related_recommended": ["73695", "2133", "1300", "39588"], "developer_recommended": ["73695", "78008"], "appid": "497", "groupid": "9", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][497]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][497]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][497]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/2094?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/2094?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-16", "version": "4.20.0", "title": "", "count": "14661", "related_recommended": ["29919", "56059", "8752", "72389"], "developer_recommended": ["381359"], "appid": "2094", "groupid": "27", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][2094]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][2094]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14661',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][2094]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1131?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/1131?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-06-07", "version": "6.1.1.10", "title": "QQ", "count": "49043", "related_recommended": ["11659", "31250", "7", "301"], "developer_recommended": ["419901", "96199", "71936", "57492"], "appid": "1131", "groupid": "27", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1131]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1131]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1131]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1294?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/1294?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "7", "update_time": "2016-05-19", "version": "6.6.1", "title": "-", "count": "35080", "related_recommended": ["50508", "2889", "3581", "125"], "developer_recommended": ["369096", "113128", "45617", "378877"], "appid": "1294", "groupid": "27", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1294]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1294]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1294]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/19903?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/19903?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-06-15", "version": "5.8.7", "title": "", "count": "17981", "related_recommended": ["55690", "58894", "28090", "1254"], "developer_recommended": ["96822", "31243", "55690", "392543"], "appid": "19903", "groupid": "3", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][19903]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][19903]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][19903]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1326?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/1326?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "10", "update_time": "2016-06-16", "version": "5.1.0.0", "title": "", "count": "147989", "related_recommended": ["1057", "81532", "33695", "85051"], "developer_recommended": ["63447", "110320", "293149", "24269"], "appid": "1326", "groupid": "6", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1326]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1326]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1326]: document already exists')
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/5?op_type=create HTTP/1.1" 409 279
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/5?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "7", "update_time": "2016-06-07", "version": "8.0.6.1363", "title": "", "count": "6882", "related_recommended": ["81816", "228", "16590", "50989"], "developer_recommended": ["326345", "81816", "88478", "110188"], "appid": "5", "groupid": "9", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][5]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][5]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][5]: document already exists')
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/96928?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/96928?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "8", "update_time": "2016-04-22", "version": "4.0.2", "title": "", "count": "9743", "related_recommended": ["23418", "99376", "72342", "89462"], "developer_recommended": [], "appid": "96928", "groupid": "23", "developer": "superpop"}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][96928]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][96928]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][96928]: document already exists')
2016-06-17 13:40:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:31 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/1127?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:31 [elasticsearch] WARNING: PUT /scrapy/items/1127?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:31 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-17", "version": "6.6.1", "title": "", "count": "341863", "related_recommended": ["34507", "16938", "58458", "323"], "developer_recommended": ["379843", "283", "97015"], "appid": "1127", "groupid": "2", "developer": ""}
2016-06-17 13:40:31 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][1127]: document already exists","shard":"2","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][1127]: document already exists","shard":"2","index":"scrapy"},"status":409}
2016-06-17 13:40:31 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341863',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][1127]: document already exists')
2016-06-17 13:40:32 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:32 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/346?op_type=create HTTP/1.1" 409 283
2016-06-17 13:40:32 [elasticsearch] WARNING: PUT /scrapy/items/346?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:32 [elasticsearch] DEBUG: > {"category": "", "rating": "6", "update_time": "2016-06-06", "version": "6.9.2", "title": "", "count": "22539", "related_recommended": ["129", "19174", "68656", "61518"], "developer_recommended": ["319980"], "appid": "346", "groupid": "2", "developer": ""}
2016-06-17 13:40:32 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][346]: document already exists","shard":"3","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][346]: document already exists","shard":"3","index":"scrapy"},"status":409}
2016-06-17 13:40:32 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][346]: document already exists')
2016-06-17 13:40:32 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:32 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/55358?op_type=create HTTP/1.1" 409 287
2016-06-17 13:40:32 [elasticsearch] WARNING: PUT /scrapy/items/55358?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:32 [elasticsearch] DEBUG: > {"category": "", "rating": "5", "update_time": "2016-05-03", "version": "4.5.1", "title": "", "count": "2442", "related_recommended": ["1076", "25855", "33749", "20649"], "developer_recommended": ["419901", "100053", "184154", "289530"], "appid": "55358", "groupid": "2", "developer": ")"}
2016-06-17 13:40:32 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][55358]: document already exists","shard":"1","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][55358]: document already exists","shard":"1","index":"scrapy"},"status":409}
2016-06-17 13:40:32 [scrapy] ERROR: Error processing {'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][55358]: document already exists')
2016-06-17 13:40:32 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:32 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/329?op_type=create HTTP/1.1" 409 283
2016-06-17 13:40:32 [elasticsearch] WARNING: PUT /scrapy/items/329?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:32 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-05-26", "version": "4.45.0.1504", "title": "", "count": "321002", "related_recommended": ["2027", "91399", "26484", "63932"], "developer_recommended": [], "appid": "329", "groupid": "6", "developer": ""}
2016-06-17 13:40:32 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][329]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][329]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:40:32 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321002',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][329]: document already exists')
2016-06-17 13:40:32 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:32 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/7055?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:32 [elasticsearch] WARNING: PUT /scrapy/items/7055?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:32 [elasticsearch] DEBUG: > {"category": "", "rating": "9", "update_time": "2016-06-13", "version": "5.21.7", "title": "-", "count": "10175", "related_recommended": ["52475", "11597", "39120", "19873"], "developer_recommended": ["89001", "103342", "80107", "52475"], "appid": "7055", "groupid": "9", "developer": ""}
2016-06-17 13:40:32 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][7055]: document already exists","shard":"4","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][7055]: document already exists","shard":"4","index":"scrapy"},"status":409}
2016-06-17 13:40:32 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][7055]: document already exists')
2016-06-17 13:40:32 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)
2016-06-17 13:40:32 [urllib3.connectionpool] DEBUG: "PUT /scrapy/items/4928?op_type=create HTTP/1.1" 409 285
2016-06-17 13:40:32 [elasticsearch] WARNING: PUT /scrapy/items/4928?op_type=create [status:409 request:0.001s]
2016-06-17 13:40:32 [elasticsearch] DEBUG: > {"category": "", "rating": "10", "update_time": "2016-06-12", "version": "5.1.0", "title": "", "count": "12099", "related_recommended": ["72617", "96743", "79984", "360"], "developer_recommended": ["80518", "59053", "11867"], "appid": "4928", "groupid": "9", "developer": ""}
2016-06-17 13:40:32 [elasticsearch] DEBUG: < {"error":{"root_cause":[{"type":"document_already_exists_exception","reason":"[items][4928]: document already exists","shard":"0","index":"scrapy"}],"type":"document_already_exists_exception","reason":"[items][4928]: document already exists","shard":"0","index":"scrapy"},"status":409}
2016-06-17 13:40:32 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 78, in process_item
    self.es.index(self.settings['ELASTICSEARCH_INDEX'], self.settings['ELASTICSEARCH_TYPE'], dict(item), id=item['appid'], op_type='create', )
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/utils.py", line 69, in _wrapped
    return func(*args, params=params, **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/client/__init__.py", line 279, in index
    _make_path(index, doc_type, id), params=params, body=body)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/transport.py", line 329, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.py", line 109, in perform_request
    self._raise_error(response.status, raw_data)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/elasticsearch/connection/base.py", line 108, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
ConflictError: TransportError(409, u'document_already_exists_exception', u'[items][4928]: document already exists')
2016-06-17 13:40:32 [scrapy] INFO: Closing spider (finished)
2016-06-17 13:40:32 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324119,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 20, 40, 32, 58128),
 'log_count/DEBUG': 244,
 'log_count/ERROR': 48,
 'log_count/INFO': 8,
 'log_count/WARNING': 49,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 20, 40, 28, 612105)}
2016-06-17 13:40:32 [scrapy] INFO: Spider closed (finished)
2016-06-17 14:23:03 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-17 14:23:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-17 14:23:03 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-17 14:23:03 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-17 14:23:03 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-17 14:23:03 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-17 14:23:03 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiSolrPipeline']
2016-06-17 14:23:03 [scrapy] INFO: Spider opened
2016-06-17 14:23:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-17 14:23:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-17 14:23:04 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-17 14:23:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-17 14:23:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/19903> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2219903%22&wt=json' (get) with body ''...
2016-06-17 14:23:05 [requests.packages.urllib3.connectionpool] INFO: Starting new HTTP connection (1): localhost
2016-06-17 14:23:05 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2219903%22&wt=json HTTP/1.1" 200 168
2016-06-17 14:23:05 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2219903%22&wt=json' (get) with body '' in 0.045 seconds, with status 200
2016-06-17 14:23:05 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:05 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:05 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:05 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:06 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.710 seconds, with status 200
2016-06-17 14:23:06 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/19903>
{'appid': u'19903',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17981',
 'developer': u'\u4e0a\u6d77\u6613\u70b9\u65f6\u7a7a\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'96822', u'31243', u'55690', u'392543'],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [u'55690', u'58894', u'28090', u'1254'],
 'title': u'\u8f66\u8f6e\u67e5\u8fdd\u7ae0\u67e5\u8be2\u5168\u56fd',
 'update_time': u'2016-06-15',
 'version': u'5.8.7'}
2016-06-17 14:23:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/55358> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2296928%22&wt=json' (get) with body ''...
2016-06-17 14:23:06 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2296928%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:06 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2296928%22&wt=json' (get) with body '' in 0.012 seconds, with status 200
2016-06-17 14:23:06 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:06 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:06 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:06 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:07 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.599 seconds, with status 200
2016-06-17 14:23:07 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/96928>
{'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9743',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
2016-06-17 14:23:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/270422> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/219> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22329%22&wt=json' (get) with body ''...
2016-06-17 14:23:07 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22329%22&wt=json HTTP/1.1" 200 165
2016-06-17 14:23:07 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22329%22&wt=json' (get) with body '' in 0.009 seconds, with status 200
2016-06-17 14:23:07 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:07 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:07 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:07 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:08 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.673 seconds, with status 200
2016-06-17 14:23:08 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/329>
{'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321006',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
2016-06-17 14:23:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221363%22&wt=json' (get) with body ''...
2016-06-17 14:23:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221363%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221363%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 14:23:08 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:08 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:08 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:08 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.599 seconds, with status 200
2016-06-17 14:23:08 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1363>
{'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29797',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
2016-06-17 14:23:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2255358%22&wt=json' (get) with body ''...
2016-06-17 14:23:08 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2255358%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:08 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2255358%22&wt=json' (get) with body '' in 0.008 seconds, with status 200
2016-06-17 14:23:08 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:08 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:08 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:08 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:09 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:09 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.545 seconds, with status 200
2016-06-17 14:23:09 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/55358>
{'appid': u'55358',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '2442',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1076', u'25855', u'33749', u'20649'],
 'title': u'\u638c\u4e0a\u82f1\u96c4\u8054\u76df',
 'update_time': u'2016-05-03',
 'version': u'4.5.1'}
2016-06-17 14:23:09 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22109%22&wt=json' (get) with body ''...
2016-06-17 14:23:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22109%22&wt=json HTTP/1.1" 200 165
2016-06-17 14:23:09 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22109%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 14:23:09 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:09 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:09 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:09 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:09 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:09 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.690 seconds, with status 200
2016-06-17 14:23:09 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/109>
{'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '74989',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
2016-06-17 14:23:09 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221357%22&wt=json' (get) with body ''...
2016-06-17 14:23:09 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221357%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:09 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221357%22&wt=json' (get) with body '' in 0.008 seconds, with status 200
2016-06-17 14:23:09 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:09 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:09 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:09 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:10 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:10 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.566 seconds, with status 200
2016-06-17 14:23:10 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1357>
{'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18203',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
2016-06-17 14:23:10 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22346%22&wt=json' (get) with body ''...
2016-06-17 14:23:10 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22346%22&wt=json HTTP/1.1" 200 165
2016-06-17 14:23:10 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22346%22&wt=json' (get) with body '' in 0.008 seconds, with status 200
2016-06-17 14:23:10 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:10 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:10 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:10 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:11 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:11 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.556 seconds, with status 200
2016-06-17 14:23:11 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/346>
{'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22539',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
2016-06-17 14:23:11 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221127%22&wt=json' (get) with body ''...
2016-06-17 14:23:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221127%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:11 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221127%22&wt=json' (get) with body '' in 0.008 seconds, with status 200
2016-06-17 14:23:11 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:11 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:11 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:11 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:11 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:11 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.585 seconds, with status 200
2016-06-17 14:23:11 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1127>
{'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '341863',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
2016-06-17 14:23:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/297> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/54719> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/13900> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/58634> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:11 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22270422%22&wt=json' (get) with body ''...
2016-06-17 14:23:11 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22270422%22&wt=json HTTP/1.1" 200 168
2016-06-17 14:23:11 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22270422%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:11 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:11 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:11 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:11 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:12 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.649 seconds, with status 200
2016-06-17 14:23:12 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/270422>
{'appid': u'270422',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '465',
 'developer': u'\u74e6\u529b\u7f51\u7edc',
 'developer_recommended': [],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u5c0f\u7c73\u76f4\u64ad',
 'update_time': u'2016-06-08',
 'version': u'1.1.18'}
2016-06-17 14:23:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221045%22&wt=json' (get) with body ''...
2016-06-17 14:23:12 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221045%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:12 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221045%22&wt=json' (get) with body '' in 0.009 seconds, with status 200
2016-06-17 14:23:12 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:12 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:12 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:12 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:13 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.692 seconds, with status 200
2016-06-17 14:23:13 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1045>
{'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '219843',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
2016-06-17 14:23:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22219%22&wt=json' (get) with body ''...
2016-06-17 14:23:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22219%22&wt=json HTTP/1.1" 200 165
2016-06-17 14:23:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22219%22&wt=json' (get) with body '' in 0.011 seconds, with status 200
2016-06-17 14:23:13 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:13 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:13 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:13 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.524 seconds, with status 200
2016-06-17 14:23:13 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/219>
{'appid': u'219',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '17386',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'3',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u767e\u5ea6\u5730\u56fe',
 'update_time': u'2016-06-06',
 'version': u'9.3.1'}
2016-06-17 14:23:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22108048%22&wt=json' (get) with body ''...
2016-06-17 14:23:13 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22108048%22&wt=json HTTP/1.1" 200 168
2016-06-17 14:23:13 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22108048%22&wt=json' (get) with body '' in 0.011 seconds, with status 200
2016-06-17 14:23:13 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:13 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:13 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:13 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:14 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:14 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.477 seconds, with status 200
2016-06-17 14:23:14 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/108048>
{'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26282',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
2016-06-17 14:23:14 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22332%22&wt=json' (get) with body ''...
2016-06-17 14:23:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22332%22&wt=json HTTP/1.1" 200 165
2016-06-17 14:23:14 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22332%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 14:23:14 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:14 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:14 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:14 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:14 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:14 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.588 seconds, with status 200
2016-06-17 14:23:14 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/332>
{'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2648',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
2016-06-17 14:23:14 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221110%22&wt=json' (get) with body ''...
2016-06-17 14:23:14 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221110%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:14 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221110%22&wt=json' (get) with body '' in 0.008 seconds, with status 200
2016-06-17 14:23:14 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:14 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:14 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:14 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:15 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:15 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.490 seconds, with status 200
2016-06-17 14:23:15 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1110>
{'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37029',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1984', u'69660', u'330724', u'360'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
2016-06-17 14:23:15 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2298%22&wt=json' (get) with body ''...
2016-06-17 14:23:15 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2298%22&wt=json HTTP/1.1" 200 164
2016-06-17 14:23:15 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2298%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 14:23:15 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:15 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:15 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:15 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 150
2016-06-17 14:23:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 1.067 seconds, with status 200
2016-06-17 14:23:16 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/98>
{'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9055',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
2016-06-17 14:23:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2271936%22&wt=json' (get) with body ''...
2016-06-17 14:23:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2271936%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2271936%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:16 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:16 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.600 seconds, with status 200
2016-06-17 14:23:16 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71936>
{'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4178',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
2016-06-17 14:23:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/31322> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/374173> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/419543> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224888%22&wt=json' (get) with body ''...
2016-06-17 14:23:16 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%224888%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:16 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224888%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 14:23:16 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:16 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:16 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:16 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:17 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.590 seconds, with status 200
2016-06-17 14:23:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4888>
{'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2168',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
2016-06-17 14:23:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22297%22&wt=json' (get) with body ''...
2016-06-17 14:23:17 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22297%22&wt=json HTTP/1.1" 200 165
2016-06-17 14:23:17 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22297%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 14:23:17 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:17 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:17 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:17 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:18 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:18 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.737 seconds, with status 200
2016-06-17 14:23:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/297>
{'appid': u'297',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '6522',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'5007', u'116315', u'8253', u'45173'],
 'groupid': u'5',
 'rating': u'4',
 'related_recommended': [u'321', u'62787', u'37993', u'5966'],
 'title': u'QQ\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-13',
 'version': u'6.7.2.2445'}
2016-06-17 14:23:18 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2254719%22&wt=json' (get) with body ''...
2016-06-17 14:23:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2254719%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:18 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2254719%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:18 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:18 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:18 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:18 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:18 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:18 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.633 seconds, with status 200
2016-06-17 14:23:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/54719>
{'appid': u'54719',
 'category': u'\u5b66\u4e60\u6559\u80b2',
 'count': '231244',
 'developer': u'\u4f5c\u4e1a\u5e2e\u6559\u80b2\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'12',
 'rating': u'9',
 'related_recommended': [u'75060', u'49915', u'48473', u'73537'],
 'title': u'\u4f5c\u4e1a\u5e2e-\u5b66\u9738\u641c\u9898',
 'update_time': u'2016-06-16',
 'version': u'6.1.0'}
2016-06-17 14:23:18 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2213900%22&wt=json' (get) with body ''...
2016-06-17 14:23:18 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2213900%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:18 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2213900%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 14:23:18 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:18 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:18 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:18 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:19 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:19 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.475 seconds, with status 200
2016-06-17 14:23:19 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/13900>
{'appid': u'13900',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '3922',
 'developer': u'\u592e\u89c6\u56fd\u9645\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'69474', u'71279', u'266237', u'43332'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'49723', u'43332', u'2889', u'63267'],
 'title': u'\u592e\u89c6\u5f71\u97f3',
 'update_time': u'2016-03-01',
 'version': u'6.0.3'}
2016-06-17 14:23:19 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221109%22&wt=json' (get) with body ''...
2016-06-17 14:23:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221109%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:19 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221109%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:19 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:19 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:19 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:19 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:19 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:19 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.488 seconds, with status 200
2016-06-17 14:23:19 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1109>
{'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69583',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
2016-06-17 14:23:19 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%228543%22&wt=json' (get) with body ''...
2016-06-17 14:23:19 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%228543%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:19 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%228543%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:19 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:19 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:19 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:19 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:20 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:20 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.528 seconds, with status 200
2016-06-17 14:23:20 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/8543>
{'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7439',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
2016-06-17 14:23:20 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2229837%22&wt=json' (get) with body ''...
2016-06-17 14:23:20 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2229837%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:20 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2229837%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 14:23:20 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:20 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:20 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:20 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.603 seconds, with status 200
2016-06-17 14:23:21 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29837>
{'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28006',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
2016-06-17 14:23:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2258634%22&wt=json' (get) with body ''...
2016-06-17 14:23:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2258634%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2258634%22&wt=json' (get) with body '' in 0.010 seconds, with status 200
2016-06-17 14:23:21 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:21 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.575 seconds, with status 200
2016-06-17 14:23:21 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/58634>
{'appid': u'58634',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '123445',
 'developer': u'\u4e50\u98ce\u521b\u60f3\uff08\u5317\u4eac\uff09\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'70764', u'72358', u'64325', u'52411'],
 'groupid': u'23',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5f00\u5fc3\u6d88\u6d88\u4e50',
 'update_time': u'2016-05-23',
 'version': u'1.33'}
2016-06-17 14:23:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/2094> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2231322%22&wt=json' (get) with body ''...
2016-06-17 14:23:21 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2231322%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:21 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2231322%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:21 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:21 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:21 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:21 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:22 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.962 seconds, with status 200
2016-06-17 14:23:22 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/31322>
{'appid': u'31322',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '11028',
 'developer': u'\u4e0a\u6d77\u5168\u571f\u8c46\u6587\u5316\u4f20\u64ad\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'1294', u'897', u'125', u'1357'],
 'title': u'\u571f\u8c46\u89c6\u9891',
 'update_time': u'2016-06-17',
 'version': u'5.8.4'}
2016-06-17 14:23:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221338%22&wt=json' (get) with body ''...
2016-06-17 14:23:22 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221338%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:22 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221338%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:22 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:22 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:22 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:22 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:23 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:23 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.674 seconds, with status 200
2016-06-17 14:23:23 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1338>
{'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24332',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
2016-06-17 14:23:23 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22323%22&wt=json' (get) with body ''...
2016-06-17 14:23:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22323%22&wt=json HTTP/1.1" 200 165
2016-06-17 14:23:23 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22323%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:23 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:23 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:23 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:23 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:23 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:23 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.575 seconds, with status 200
2016-06-17 14:23:23 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/323>
{'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3446',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
2016-06-17 14:23:23 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22374173%22&wt=json' (get) with body ''...
2016-06-17 14:23:23 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22374173%22&wt=json HTTP/1.1" 200 168
2016-06-17 14:23:23 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22374173%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:23 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:23 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:23 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:23 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:24 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:24 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.547 seconds, with status 200
2016-06-17 14:23:24 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/374173>
{'appid': u'374173',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '1346',
 'developer': u'\u5317\u4eac\u521b\u610f\u6bd4\u7279\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'117302', u'80542', u'311330', u'257019'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u8d5b\u5c14\u53f7\u4e4b\u70c8\u706b\u82cd\u7a79',
 'update_time': u'2016-06-08',
 'version': u'1.3.1'}
2016-06-17 14:23:24 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2222704%22&wt=json' (get) with body ''...
2016-06-17 14:23:24 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2222704%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:24 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2222704%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:24 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:24 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:24 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:24 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:25 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:25 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.570 seconds, with status 200
2016-06-17 14:23:25 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/22704>
{'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22269',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
2016-06-17 14:23:25 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22118%22&wt=json' (get) with body ''...
2016-06-17 14:23:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22118%22&wt=json HTTP/1.1" 200 165
2016-06-17 14:23:25 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22118%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 14:23:25 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:25 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:25 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:25 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:25 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:25 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.582 seconds, with status 200
2016-06-17 14:23:25 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/118>
{'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
2016-06-17 14:23:25 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2210411%22&wt=json' (get) with body ''...
2016-06-17 14:23:25 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2210411%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:25 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2210411%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:25 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:25 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:25 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:25 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:26 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:26 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.551 seconds, with status 200
2016-06-17 14:23:26 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/10411>
{'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7681',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
2016-06-17 14:23:26 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22419543%22&wt=json' (get) with body ''...
2016-06-17 14:23:26 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22419543%22&wt=json HTTP/1.1" 200 168
2016-06-17 14:23:26 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22419543%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 14:23:26 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:26 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:26 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:26 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:27 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 150
2016-06-17 14:23:27 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 1.071 seconds, with status 200
2016-06-17 14:23:27 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/419543>
{'appid': u'419543',
 'category': u'\u7f51\u6e38RPG',
 'count': '101',
 'developer': u'\u5317\u4eac\u74e6\u529b\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'19',
 'rating': u'6',
 'related_recommended': [],
 'title': u'\u5251\u4fa0\u60c5\u7f18',
 'update_time': u'2016-06-16',
 'version': u'1.3.1'}
2016-06-17 14:23:27 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:27 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:27 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:27 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:27 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:27 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:27 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-17 14:23:27 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%229744%22&wt=json' (get) with body ''...
2016-06-17 14:23:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%229744%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:27 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%229744%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 14:23:27 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:27 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:27 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:27 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:27 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:27 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.566 seconds, with status 200
2016-06-17 14:23:27 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/9744>
{'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10661',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
2016-06-17 14:23:27 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221294%22&wt=json' (get) with body ''...
2016-06-17 14:23:27 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221294%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:27 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221294%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:27 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:27 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:27 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:27 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:28 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:28 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.631 seconds, with status 200
2016-06-17 14:23:28 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1294>
{'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35080',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
2016-06-17 14:23:28 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221131%22&wt=json' (get) with body ''...
2016-06-17 14:23:28 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221131%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:28 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221131%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:28 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:28 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:28 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:28 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:29 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:29 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.483 seconds, with status 200
2016-06-17 14:23:29 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1131>
{'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49043',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
2016-06-17 14:23:29 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%222094%22&wt=json' (get) with body ''...
2016-06-17 14:23:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%222094%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:29 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%222094%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 14:23:29 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:29 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:29 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:29 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:29 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:29 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.494 seconds, with status 200
2016-06-17 14:23:29 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/2094>
{'appid': u'2094',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '14662',
 'developer': u'\u4e0a\u6d77\u5e7b\u7535\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'381359'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'29919', u'56059', u'8752', u'72389'],
 'title': u'\u54d4\u54e9\u54d4\u54e9\u52a8\u753b',
 'update_time': u'2016-06-16',
 'version': u'4.20.0'}
2016-06-17 14:23:29 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22497%22&wt=json' (get) with body ''...
2016-06-17 14:23:29 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22497%22&wt=json HTTP/1.1" 200 165
2016-06-17 14:23:29 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22497%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:29 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:29 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:29 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:29 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:30 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:30 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.525 seconds, with status 200
2016-06-17 14:23:30 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/497>
{'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93056',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
2016-06-17 14:23:30 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221326%22&wt=json' (get) with body ''...
2016-06-17 14:23:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221326%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:30 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221326%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:30 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:30 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:30 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:30 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:30 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:30 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.489 seconds, with status 200
2016-06-17 14:23:30 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1326>
{'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147989',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
2016-06-17 14:23:30 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225%22&wt=json' (get) with body ''...
2016-06-17 14:23:30 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%225%22&wt=json HTTP/1.1" 200 163
2016-06-17 14:23:30 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:30 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:30 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:30 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:30 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:31 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:31 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.718 seconds, with status 200
2016-06-17 14:23:31 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5>
{'appid': u'5',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '6882',
 'developer': u'\u676d\u5dde\u5377\u74dc\u7f51\u7edc\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'326345', u'81816', u'88478', u'110188'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'81816', u'228', u'16590', u'50989'],
 'title': u'\u8611\u83c7\u8857',
 'update_time': u'2016-06-07',
 'version': u'8.0.6.1363'}
2016-06-17 14:23:31 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2239086%22&wt=json' (get) with body ''...
2016-06-17 14:23:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%2239086%22&wt=json HTTP/1.1" 200 167
2016-06-17 14:23:31 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%2239086%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:31 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:31 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:31 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:31 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:31 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:31 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.477 seconds, with status 200
2016-06-17 14:23:31 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/39086>
{'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10987',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
2016-06-17 14:23:31 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225314%22&wt=json' (get) with body ''...
2016-06-17 14:23:31 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%225314%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:31 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%225314%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:31 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:31 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:31 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:31 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:32 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:32 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.600 seconds, with status 200
2016-06-17 14:23:32 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5314>
{'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12640',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'378879', u'1100', u'98666'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
2016-06-17 14:23:32 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221359%22&wt=json' (get) with body ''...
2016-06-17 14:23:32 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221359%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:32 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221359%22&wt=json' (get) with body '' in 0.006 seconds, with status 200
2016-06-17 14:23:32 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:32 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:32 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:32 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.770 seconds, with status 200
2016-06-17 14:23:33 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1359>
{'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133577',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
2016-06-17 14:23:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221122%22&wt=json' (get) with body ''...
2016-06-17 14:23:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221122%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221122%22&wt=json' (get) with body '' in 0.008 seconds, with status 200
2016-06-17 14:23:33 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:33 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.590 seconds, with status 200
2016-06-17 14:23:33 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1122>
{'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121772',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
2016-06-17 14:23:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221023%22&wt=json' (get) with body ''...
2016-06-17 14:23:33 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%221023%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:33 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%221023%22&wt=json' (get) with body '' in 0.005 seconds, with status 200
2016-06-17 14:23:33 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:33 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:33 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:33 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:34 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.954 seconds, with status 200
2016-06-17 14:23:34 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1023>
{'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '253978',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
2016-06-17 14:23:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22125%22&wt=json' (get) with body ''...
2016-06-17 14:23:34 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%22125%22&wt=json HTTP/1.1" 200 165
2016-06-17 14:23:34 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%22125%22&wt=json' (get) with body '' in 0.007 seconds, with status 200
2016-06-17 14:23:34 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:34 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:34 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:34 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:35 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:35 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.578 seconds, with status 200
2016-06-17 14:23:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/125>
{'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54001',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
2016-06-17 14:23:35 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224928%22&wt=json' (get) with body ''...
2016-06-17 14:23:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%224928%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:35 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%224928%22&wt=json' (get) with body '' in 0.008 seconds, with status 200
2016-06-17 14:23:35 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:35 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:35 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:35 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:35 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:35 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.472 seconds, with status 200
2016-06-17 14:23:35 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4928>
{'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12099',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
2016-06-17 14:23:35 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%227055%22&wt=json' (get) with body ''...
2016-06-17 14:23:35 [requests.packages.urllib3.connectionpool] DEBUG: "GET /solr/scrapy/select/?q=appid%3A%227055%22&wt=json HTTP/1.1" 200 166
2016-06-17 14:23:35 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/select/?q=appid%3A%227055%22&wt=json' (get) with body '' in 0.008 seconds, with status 200
2016-06-17 14:23:35 [pysolr] DEBUG: Found '0' search results.
2016-06-17 14:23:35 [pysolr] DEBUG: Starting to build add request...
2016-06-17 14:23:35 [pysolr] DEBUG: Built add request of 1 docs in 0.00 seconds.
2016-06-17 14:23:35 [pysolr] DEBUG: Starting request to 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do'...
2016-06-17 14:23:36 [requests.packages.urllib3.connectionpool] DEBUG: "POST /solr/scrapy/update/?commit=true HTTP/1.1" 200 149
2016-06-17 14:23:36 [pysolr] INFO: Finished 'http://localhost:8983/solr/scrapy/update/?commit=true' (post) with body 'u'<add><do' in 0.564 seconds, with status 200
2016-06-17 14:23:36 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/7055>
{'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10175',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
2016-06-17 14:23:36 [scrapy] INFO: Closing spider (finished)
2016-06-17 14:23:36 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15344,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 324327,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 17, 21, 23, 36, 429544),
 'item_scraped_count': 48,
 'log_count/DEBUG': 436,
 'log_count/INFO': 104,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 17, 21, 23, 3, 905898)}
2016-06-17 14:23:36 [scrapy] INFO: Spider closed (finished)
2016-06-18 09:14:01 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-18 09:14:01 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-18 09:14:01 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-18 09:14:01 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-18 09:14:01 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-18 09:14:01 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-18 09:14:01 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiMongoDBPipeline']
2016-06-18 09:14:01 [scrapy] INFO: Spider opened
2016-06-18 09:14:01 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:14:01 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-18 09:14:01 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-18 09:14:04 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-18 09:14:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:05 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '254497',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/112109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/405279> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:05 [scrapy] ERROR: Error processing {'appid': u'112109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '1067',
 'developer': u'MIUI\u8bba\u575b',
 'developer_recommended': [],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [],
 'title': u'MIUI\u8bba\u575b',
 'update_time': u'2016-06-06',
 'version': u'2.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:05 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12136',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:05 [scrapy] ERROR: Error processing {'appid': u'405279',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '43',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'2',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000\u52a9\u624b',
 'update_time': u'2016-06-06',
 'version': u'1.0.1.603'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:05 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18216',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:06 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10998',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:06 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2665',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:06 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54035',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:06 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133632',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:06 [scrapy] ERROR: Error processing {'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10205',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:06 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3450',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:06 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '220377',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:06 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22375',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5027> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:07 [scrapy] ERROR: Error processing {'appid': u'5027',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1225',
 'developer': u'\u5357\u4eac\u82cf\u5b81\u6613\u8d2d\u7535\u5b50\u5546\u52a1\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'49061'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'56049', u'11597', u'9531', u'51027'],
 'title': u'\u82cf\u5b81\u6613\u8d2d-\u5e74\u4e2d\u5927\u4fc3',
 'update_time': u'2016-06-17',
 'version': u'4.2.6'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:07 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:07 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4203',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:07 [scrapy] ERROR: Error processing {'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69614',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:07 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26449',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:07 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24346',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/89336> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:07 [scrapy] ERROR: Error processing {'appid': u'89336',
 'category': u'\u6a21\u62df\u7ecf\u8425',
 'count': '9120',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8\u73e0\u6d77\u5206\u516c\u53f8',
 'developer_recommended': [u'100739', u'70869', u'404995', u'364950'],
 'groupid': u'29',
 'rating': u'9',
 'related_recommended': [u'89462', u'96776', u'72342', u'94160'],
 'title': u'\u591a\u73a9\u6211\u7684\u4e16\u754c\u76d2\u5b50',
 'update_time': u'2016-06-08',
 'version': u'1.6.26'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:07 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:08 [scrapy] ERROR: Error processing {'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147994',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/48217> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:08 [scrapy] ERROR: Error processing {'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '342329',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/121542> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:08 [scrapy] ERROR: Error processing {'appid': u'48217',
 'category': u'\u8dd1\u9177\u95ef\u5173',
 'count': '113196',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'329513', u'54227', u'77714', u'33013'],
 'groupid': u'26',
 'rating': u'7',
 'related_recommended': [u'45078', u'44197', u'57492', u'68657'],
 'title': u'\u5929\u5929\u9177\u8dd1',
 'update_time': u'2016-06-03',
 'version': u'1.0.34.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:08 [scrapy] ERROR: Error processing {'appid': u'121542',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '15335',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u7a7f\u8d8a\u706b\u7ebf\uff1a\u67aa\u6218\u738b\u8005',
 'update_time': u'2016-04-28',
 'version': u'1.0.7.60'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:08 [scrapy] ERROR: Error processing {'appid': u'29',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '21286',
 'developer': u'\u5317\u4eac\u641c\u72d7\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1284', u'3021', u'37993', u'168890'],
 'groupid': u'5',
 'rating': u'9',
 'related_recommended': [u'33664', u'37993', u'52597', u'3021'],
 'title': u'\u641c\u72d7\u8f93\u5165\u6cd5',
 'update_time': u'2016-05-27',
 'version': u'8.2.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71600> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:08 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/18076> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:08 [scrapy] ERROR: Error processing {'appid': u'71600',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '2013',
 'developer': u'\u5317\u4eac\u5c0f\u5ea6\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'81775'],
 'groupid': u'4',
 'rating': u'10',
 'related_recommended': [u'98717', u'2133', u'56249', u'48956'],
 'title': u'\u767e\u5ea6\u5916\u5356',
 'update_time': u'2016-06-16',
 'version': u'3.9.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:08 [scrapy] ERROR: Error processing {'appid': u'18076',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '11975',
 'developer': u'\u62c9\u624e\u65af\u7f51\u7edc\u79d1\u6280\uff08\u4e0a\u6d77\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'346753', u'120094', u'119616'],
 'groupid': u'4',
 'rating': u'8',
 'related_recommended': [u'48956', u'98717', u'56249', u'2133'],
 'title': u'\u997f\u4e86\u4e48',
 'update_time': u'2016-06-12',
 'version': u'5.11'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:09 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:09 [scrapy] ERROR: Error processing {'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2175',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:09 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:09 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:09 [scrapy] ERROR: Error processing {'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7449',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:09 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28030',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:09 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:10 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10671',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:10 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/24269> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:10 [scrapy] ERROR: Error processing {'appid': u'24269',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '63275',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'1326', u'110320', u'293149'],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'94392', u'91399', u'33662', u'63932'],
 'title': u'\u7f8e\u989c\u76f8\u673a',
 'update_time': u'2016-06-13',
 'version': u'4.6.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:10 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:10 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:10 [scrapy] ERROR: Error processing {'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93168',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:10 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:10 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:10 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1117> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:10 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37049',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:10 [scrapy] ERROR: Error processing {'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29818',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:10 [scrapy] ERROR: Error processing {'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321544',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:10 [scrapy] ERROR: Error processing {'appid': u'1117',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '9272',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [u'32351', u'58458', u'50401', u'75942'],
 'title': u'QQ\u7a7a\u95f4',
 'update_time': u'2016-06-08',
 'version': u'6.5.4.288'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:11 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49093',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/50816> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:11 [scrapy] ERROR: Error processing {'appid': u'50816',
 'category': u'\u56fe\u4e66\u9605\u8bfb',
 'count': '44493',
 'developer': u'\u6df1\u5733\u5e02\u5b9c\u641c\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'57598', u'113904', u'363008', u'80324'],
 'groupid': u'7',
 'rating': u'9',
 'related_recommended': [u'80596', u'71089', u'11121', u'87667'],
 'title': u'\u5b9c\u641c\u5c0f\u8bf4',
 'update_time': u'2016-05-30',
 'version': u'2.10.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:11 [scrapy] ERROR: Error processing {'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22567',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:11 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35096',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:11 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/53109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:11 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7713',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:11 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12658',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:11 [scrapy] ERROR: Error processing {'appid': u'53109',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1076',
 'developer': u'\u4e07\u8fbe\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'54516', u'9531', u'33976', u'67284'],
 'title': u'\u98de\u51e1',
 'update_time': u'2016-06-02',
 'version': u'4.2.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:12 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121924',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:12 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:12 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '75027',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:14 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:14 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9808',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:14:17 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9075',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 147, in process_item
    condition = str(self.key) + ':' + '"' + self.__get_itemvalue__(item, item[self.key]) + '"'
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 161, in __get_itemvalue__
    raise TypeError('Only string and list are valid sources')
TypeError: Only string and list are valid sources
2016-06-18 09:14:17 [scrapy] INFO: Closing spider (finished)
2016-06-18 09:14:17 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15348,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 321523,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 18, 16, 14, 17, 767963),
 'log_count/DEBUG': 52,
 'log_count/ERROR': 48,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 18, 16, 14, 1, 303176)}
2016-06-18 09:14:17 [scrapy] INFO: Spider closed (finished)
2016-06-18 09:15:48 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-18 09:15:48 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-18 09:15:48 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-18 09:15:48 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-18 09:15:48 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-18 09:15:48 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-18 09:15:48 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiMongoDBPipeline']
2016-06-18 09:15:48 [scrapy] INFO: Spider opened
2016-06-18 09:15:48 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:15:48 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-18 09:15:50 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-18 09:15:54 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-18 09:16:21 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:22 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/112109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:52 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10998',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    result = self.collection.find_one(condition)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:16:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:16:52 [scrapy] INFO: Crawled 13 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:17:23 [scrapy] ERROR: Error processing {'appid': u'112109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '1067',
 'developer': u'MIUI\u8bba\u575b',
 'developer_recommended': [],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [],
 'title': u'MIUI\u8bba\u575b',
 'update_time': u'2016-06-06',
 'version': u'2.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    result = self.collection.find_one(condition)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:17:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/48217> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:17:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1117> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:17:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:17:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:17:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:17:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:17:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:17:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:17:53 [scrapy] ERROR: Error processing {'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18216',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    result = self.collection.find_one(condition)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:18:23 [scrapy] ERROR: Error processing {'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2665',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    result = self.collection.find_one(condition)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:18:31 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2016-06-18 09:18:53 [scrapy] ERROR: Error processing {'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26449',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    result = self.collection.find_one(condition)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:19:23 [scrapy] ERROR: Error processing {'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54035',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    result = self.collection.find_one(condition)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:19:53 [scrapy] ERROR: Error processing {'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133633',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    search_filter = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:20:23 [scrapy] ERROR: Error processing {'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '220377',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    search_filter = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:20:53 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9075',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    search_filter = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:21:23 [scrapy] ERROR: Error processing {'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4204',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    search_filter = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:21:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:21:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/89336> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:21:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5027> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:21:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:21:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:21:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:21:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71600> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:21:23 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:21:23 [scrapy] INFO: Closing spider (shutdown)
2016-06-18 09:21:23 [scrapy] INFO: Crawled 29 pages (at 16 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:21:53 [scrapy] ERROR: Error processing {'appid': u'48217',
 'category': u'\u8dd1\u9177\u95ef\u5173',
 'count': '113196',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'329513', u'54227', u'77714', u'33013'],
 'groupid': u'26',
 'rating': u'7',
 'related_recommended': [u'45078', u'44197', u'57492', u'68657'],
 'title': u'\u5929\u5929\u9177\u8dd1',
 'update_time': u'2016-06-03',
 'version': u'1.0.34.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    search_filter = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:22:23 [scrapy] ERROR: Error processing {'appid': u'1117',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '9272',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [u'32351', u'58458', u'50401', u'75942'],
 'title': u'QQ\u7a7a\u95f4',
 'update_time': u'2016-06-08',
 'version': u'6.5.4.288'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    search_filter = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:22:54 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22376',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    search_filter = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:23:24 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3450',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'102772', u'396151', u'87320', u'10408'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    search_filter = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:23:54 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '75027',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:24:24 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37049',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:24:54 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49093',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:25:24 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7713',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:25:24 [scrapy] INFO: Crawled 29 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:25:24 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/1127> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/1127 took longer than 180.0 seconds..
2016-06-18 09:25:24 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/121542> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/121542 took longer than 180.0 seconds..
2016-06-18 09:25:24 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/29> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/29 took longer than 180.0 seconds..
2016-06-18 09:25:24 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/24269> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/24269 took longer than 180.0 seconds..
2016-06-18 09:25:24 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/18076> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/18076 took longer than 180.0 seconds..
2016-06-18 09:25:24 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/8543> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/8543 took longer than 180.0 seconds..
2016-06-18 09:25:24 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/4888> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/4888 took longer than 180.0 seconds..
2016-06-18 09:25:24 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/497> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/497 took longer than 180.0 seconds..
2016-06-18 09:25:54 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24346',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:26:24 [scrapy] ERROR: Error processing {'appid': u'89336',
 'category': u'\u6a21\u62df\u7ecf\u8425',
 'count': '9120',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8\u73e0\u6d77\u5206\u516c\u53f8',
 'developer_recommended': [u'100739', u'70869', u'404995', u'364950'],
 'groupid': u'29',
 'rating': u'9',
 'related_recommended': [u'89462', u'96776', u'72342', u'94160'],
 'title': u'\u591a\u73a9\u6211\u7684\u4e16\u754c\u76d2\u5b50',
 'update_time': u'2016-06-08',
 'version': u'1.6.26'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:26:54 [scrapy] ERROR: Error processing {'appid': u'5027',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1225',
 'developer': u'\u5357\u4eac\u82cf\u5b81\u6613\u8d2d\u7535\u5b50\u5546\u52a1\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'49061'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'56049', u'11597', u'9531', u'51027'],
 'title': u'\u82cf\u5b81\u6613\u8d2d-\u5e74\u4e2d\u5927\u4fc3',
 'update_time': u'2016-06-17',
 'version': u'4.2.6'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    result = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:27:24 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    result = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:27:53 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2016-06-18 09:27:54 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28030',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 149, in process_item
    result = {}
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:28:15 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-18 09:28:15 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-18 09:28:15 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-18 09:28:15 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-18 09:28:15 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-18 09:28:16 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-18 09:28:16 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiMongoDBPipeline']
2016-06-18 09:28:16 [scrapy] INFO: Spider opened
2016-06-18 09:28:16 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:28:16 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-06-18 09:28:16 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-18 09:28:16 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/405279> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:156: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  level=log.DEBUG, spider=spider)

2016-06-18 09:28:17 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/405279>
{'appid': u'405279',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '43',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'2',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000\u52a9\u624b',
 'update_time': u'2016-06-06',
 'version': u'1.0.1.603'}
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/112109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/98>
{'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9075',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
2016-06-18 09:28:17 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71936>
{'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4204',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
2016-06-18 09:28:17 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1359>
{'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133633',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
2016-06-18 09:28:17 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1045>
{'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '220381',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
2016-06-18 09:28:17 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/112109>
{'appid': u'112109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '1067',
 'developer': u'MIUI\u8bba\u575b',
 'developer_recommended': [],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [],
 'title': u'MIUI\u8bba\u575b',
 'update_time': u'2016-06-06',
 'version': u'2.6.1'}
2016-06-18 09:28:17 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1357>
{'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18216',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
2016-06-18 09:28:17 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/108048>
{'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26449',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71600> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/121542> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:17 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:17 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/332>
{'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2666',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/125>
{'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54035',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71600>
{'appid': u'71600',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '2013',
 'developer': u'\u5317\u4eac\u5c0f\u5ea6\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'81775'],
 'groupid': u'4',
 'rating': u'10',
 'related_recommended': [u'98717', u'2133', u'56249', u'48956'],
 'title': u'\u767e\u5ea6\u5916\u5356',
 'update_time': u'2016-06-16',
 'version': u'3.9.0'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1127>
{'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '342333',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/121542>
{'appid': u'121542',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '15335',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u7a7f\u8d8a\u706b\u7ebf\uff1a\u67aa\u6218\u738b\u8005',
 'update_time': u'2016-04-28',
 'version': u'1.0.7.60'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1326>
{'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147994',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29>
{'appid': u'29',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '21286',
 'developer': u'\u5317\u4eac\u641c\u72d7\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1284', u'352553', u'33664', u'37993'],
 'groupid': u'5',
 'rating': u'9',
 'related_recommended': [u'33664', u'37993', u'52597', u'3021'],
 'title': u'\u641c\u72d7\u8f93\u5165\u6cd5',
 'update_time': u'2016-05-27',
 'version': u'8.2.1'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/89336> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5027> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/22704>
{'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22376',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/323>
{'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3450',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'102772', u'396151', u'87320', u'10408'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/89336>
{'appid': u'89336',
 'category': u'\u6a21\u62df\u7ecf\u8425',
 'count': '9120',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8\u73e0\u6d77\u5206\u516c\u53f8',
 'developer_recommended': [u'100739', u'70869', u'404995', u'364950'],
 'groupid': u'29',
 'rating': u'9',
 'related_recommended': [u'89462', u'96776', u'72342', u'94160'],
 'title': u'\u591a\u73a9\u6211\u7684\u4e16\u754c\u76d2\u5b50',
 'update_time': u'2016-06-08',
 'version': u'1.6.26'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5027>
{'appid': u'5027',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1225',
 'developer': u'\u5357\u4eac\u82cf\u5b81\u6613\u8d2d\u7535\u5b50\u5546\u52a1\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'49061'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'56049', u'11597', u'9531', u'51027'],
 'title': u'\u82cf\u5b81\u6613\u8d2d-\u5e74\u4e2d\u5927\u4fc3',
 'update_time': u'2016-06-17',
 'version': u'4.2.6'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1338>
{'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24346',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29837>
{'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28030',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/24269> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/18076> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/39086>
{'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10998',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/118>
{'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/9744>
{'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10672',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/24269>
{'appid': u'24269',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '63275',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'1326', u'110320', u'293149'],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'94392', u'91399', u'33662', u'63932'],
 'title': u'\u7f8e\u989c\u76f8\u673a',
 'update_time': u'2016-06-13',
 'version': u'4.6.5.0'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/18076>
{'appid': u'18076',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '11975',
 'developer': u'\u62c9\u624e\u65af\u7f51\u7edc\u79d1\u6280\uff08\u4e0a\u6d77\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'346753', u'120094', u'119616'],
 'groupid': u'4',
 'rating': u'8',
 'related_recommended': [u'48956', u'98717', u'56249', u'2133'],
 'title': u'\u997f\u4e86\u4e48',
 'update_time': u'2016-06-12',
 'version': u'5.11'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/8543>
{'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7449',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4888>
{'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2175',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/497>
{'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93169',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/329>
{'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321550',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/48217> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1117> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/346>
{'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22567',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1363>
{'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29818',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/7055>
{'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10205',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1109>
{'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69615',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/48217>
{'appid': u'48217',
 'category': u'\u8dd1\u9177\u95ef\u5173',
 'count': '113196',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'329513', u'54227', u'77714', u'33013'],
 'groupid': u'26',
 'rating': u'7',
 'related_recommended': [u'45078', u'44197', u'57492', u'68657'],
 'title': u'\u5929\u5929\u9177\u8dd1',
 'update_time': u'2016-06-03',
 'version': u'1.0.34.0'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/109>
{'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '75027',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1117>
{'appid': u'1117',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '9272',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [u'32351', u'58458', u'50401', u'75942'],
 'title': u'QQ\u7a7a\u95f4',
 'update_time': u'2016-06-08',
 'version': u'6.5.4.288'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1110>
{'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37049',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/50816> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/53109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1131>
{'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49093',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/10411>
{'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7713',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1294>
{'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35096',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/50816>
{'appid': u'50816',
 'category': u'\u56fe\u4e66\u9605\u8bfb',
 'count': '44495',
 'developer': u'\u6df1\u5733\u5e02\u5b9c\u641c\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'57598', u'113904', u'363008', u'80324'],
 'groupid': u'7',
 'rating': u'9',
 'related_recommended': [u'80596', u'71089', u'11121', u'87667'],
 'title': u'\u5b9c\u641c\u5c0f\u8bf4',
 'update_time': u'2016-05-30',
 'version': u'2.10.0'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/53109>
{'appid': u'53109',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1076',
 'developer': u'\u4e07\u8fbe\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'54516', u'9531', u'33976', u'67284'],
 'title': u'\u98de\u51e1',
 'update_time': u'2016-06-02',
 'version': u'4.2.1.0'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1122>
{'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121925',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5314>
{'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12659',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/96928>
{'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9808',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
2016-06-18 09:28:18 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:28:18 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:18 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1023>
{'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '254501',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
2016-06-18 09:28:19 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:28:19 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4928>
{'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12136',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
2016-06-18 09:28:19 [scrapy] INFO: Closing spider (finished)
2016-06-18 09:28:19 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15348,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 321580,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 18, 16, 28, 19, 46031),
 'item_scraped_count': 48,
 'log_count/DEBUG': 148,
 'log_count/INFO': 7,
 'log_count/WARNING': 2,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 18, 16, 28, 16, 31851)}
2016-06-18 09:28:19 [scrapy] INFO: Spider closed (finished)
2016-06-18 09:29:49 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-18 09:29:49 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-18 09:29:49 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-18 09:29:49 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-18 09:29:49 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-18 09:29:49 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-18 09:29:49 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiMongoDBPipeline']
2016-06-18 09:29:49 [scrapy] INFO: Spider opened
2016-06-18 09:29:49 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:29:49 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-06-18 09:29:51 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-18 09:29:51 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-18 09:29:51 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:156: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  level=log.DEBUG, spider=spider)

2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1131>
{'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49093',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/50816> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/53109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/10411>
{'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7713',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1023>
{'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '254501',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/50816>
{'appid': u'50816',
 'category': u'\u56fe\u4e66\u9605\u8bfb',
 'count': '44495',
 'developer': u'\u6df1\u5733\u5e02\u5b9c\u641c\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'57598', u'113904', u'363008', u'80324'],
 'groupid': u'7',
 'rating': u'9',
 'related_recommended': [u'80596', u'71089', u'11121', u'87667'],
 'title': u'\u5b9c\u641c\u5c0f\u8bf4',
 'update_time': u'2016-05-30',
 'version': u'2.10.0'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1294>
{'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35096',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/53109>
{'appid': u'53109',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1076',
 'developer': u'\u4e07\u8fbe\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'54516', u'9531', u'33976', u'67284'],
 'title': u'\u98de\u51e1',
 'update_time': u'2016-06-02',
 'version': u'4.2.1.0'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1122>
{'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121925',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5314>
{'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12659',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'378879', u'1100', u'98666'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/405279> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/405279>
{'appid': u'405279',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '43',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'2',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000\u52a9\u624b',
 'update_time': u'2016-06-06',
 'version': u'1.0.1.603'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/98>
{'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9075',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1357>
{'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18216',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1045>
{'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '220387',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4928>
{'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12136',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/89336> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/39086>
{'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10998',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/22704>
{'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22376',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/323>
{'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3450',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5027> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1338>
{'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24346',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
2016-06-18 09:29:52 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:52 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/89336>
{'appid': u'89336',
 'category': u'\u6a21\u62df\u7ecf\u8425',
 'count': '9120',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8\u73e0\u6d77\u5206\u516c\u53f8',
 'developer_recommended': [u'100739', u'70869', u'404995', u'364950'],
 'groupid': u'29',
 'rating': u'9',
 'related_recommended': [u'89462', u'96776', u'72342', u'94160'],
 'title': u'\u591a\u73a9\u6211\u7684\u4e16\u754c\u76d2\u5b50',
 'update_time': u'2016-06-08',
 'version': u'1.6.26'}
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:52 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71600> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5027>
{'appid': u'5027',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1225',
 'developer': u'\u5357\u4eac\u82cf\u5b81\u6613\u8d2d\u7535\u5b50\u5546\u52a1\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'49061'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'56049', u'11597', u'9531', u'51027'],
 'title': u'\u82cf\u5b81\u6613\u8d2d-\u5e74\u4e2d\u5927\u4fc3',
 'update_time': u'2016-06-17',
 'version': u'4.2.6'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29837>
{'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28031',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/9744>
{'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10672',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/118>
{'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71600>
{'appid': u'71600',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '2013',
 'developer': u'\u5317\u4eac\u5c0f\u5ea6\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'81775'],
 'groupid': u'4',
 'rating': u'10',
 'related_recommended': [u'98717', u'2133', u'56249', u'48956'],
 'title': u'\u767e\u5ea6\u5916\u5356',
 'update_time': u'2016-06-16',
 'version': u'3.9.0'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/121542> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1326>
{'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147994',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/24269> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1127>
{'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '342337',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/18076> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/121542>
{'appid': u'121542',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '15335',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u7a7f\u8d8a\u706b\u7ebf\uff1a\u67aa\u6218\u738b\u8005',
 'update_time': u'2016-04-28',
 'version': u'1.0.7.60'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71936>
{'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4204',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29>
{'appid': u'29',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '21286',
 'developer': u'\u5317\u4eac\u641c\u72d7\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1284', u'352553', u'33664', u'37993'],
 'groupid': u'5',
 'rating': u'9',
 'related_recommended': [u'33664', u'37993', u'52597', u'3021'],
 'title': u'\u641c\u72d7\u8f93\u5165\u6cd5',
 'update_time': u'2016-05-27',
 'version': u'8.2.1'}
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/24269>
{'appid': u'24269',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '63275',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'1326', u'110320', u'293149'],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'94392', u'91399', u'33662', u'63932'],
 'title': u'\u7f8e\u989c\u76f8\u673a',
 'update_time': u'2016-06-13',
 'version': u'4.6.5.0'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/18076>
{'appid': u'18076',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '11975',
 'developer': u'\u62c9\u624e\u65af\u7f51\u7edc\u79d1\u6280\uff08\u4e0a\u6d77\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'346753', u'120094', u'119616'],
 'groupid': u'4',
 'rating': u'8',
 'related_recommended': [u'48956', u'98717', u'56249', u'2133'],
 'title': u'\u997f\u4e86\u4e48',
 'update_time': u'2016-06-12',
 'version': u'5.11'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/96928>
{'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9808',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/8543>
{'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7449',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4888>
{'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2175',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/497>
{'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93169',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/48217> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/329>
{'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321550',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/346>
{'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22567',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1363>
{'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29818',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/7055>
{'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10205',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/48217>
{'appid': u'48217',
 'category': u'\u8dd1\u9177\u95ef\u5173',
 'count': '113196',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'329513', u'54227', u'77714', u'33013'],
 'groupid': u'26',
 'rating': u'7',
 'related_recommended': [u'45078', u'44197', u'57492', u'68657'],
 'title': u'\u5929\u5929\u9177\u8dd1',
 'update_time': u'2016-06-03',
 'version': u'1.0.34.0'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1117> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1109>
{'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69615',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/112109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/109>
{'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '75027',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1110>
{'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37052',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1117>
{'appid': u'1117',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '9272',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [u'32351', u'58458', u'50401', u'75942'],
 'title': u'QQ\u7a7a\u95f4',
 'update_time': u'2016-06-08',
 'version': u'6.5.4.288'}
2016-06-18 09:29:53 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/112109>
{'appid': u'112109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '1067',
 'developer': u'MIUI\u8bba\u575b',
 'developer_recommended': [],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [],
 'title': u'MIUI\u8bba\u575b',
 'update_time': u'2016-06-06',
 'version': u'2.6.1'}
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/108048>
{'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26449',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1359>
{'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133633',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/332>
{'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2666',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
2016-06-18 09:29:53 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 09:29:53 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/125>
{'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54035',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
2016-06-18 09:29:53 [scrapy] INFO: Closing spider (finished)
2016-06-18 09:29:53 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15348,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 321543,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 18, 16, 29, 53, 781627),
 'item_scraped_count': 48,
 'log_count/DEBUG': 148,
 'log_count/INFO': 7,
 'log_count/WARNING': 2,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 18, 16, 29, 49, 822733)}
2016-06-18 09:29:53 [scrapy] INFO: Spider closed (finished)
2016-06-18 09:41:03 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-18 09:41:03 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-18 09:41:03 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-18 09:41:03 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-18 09:41:03 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-18 09:41:03 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-18 09:41:03 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiMongoDBPipeline']
2016-06-18 09:41:03 [scrapy] INFO: Spider opened
2016-06-18 09:41:03 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:41:03 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6024
2016-06-18 09:41:04 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-18 09:41:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-18 09:41:05 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:41:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:41:36 [scrapy] ERROR: Error processing {'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '75027',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:41:36 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:41:36 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:41:36 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:41:36 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:41:36 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/53109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:41:36 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:41:36 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1117> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:41:36 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/50816> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:42:06 [scrapy] ERROR: Error processing {'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37052',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:42:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:42:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:42:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:42:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:42:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:42:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:42:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:42:06 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/405279> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:42:06 [scrapy] INFO: Crawled 20 pages (at 20 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:42:36 [scrapy] ERROR: Error processing {'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49093',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:43:06 [scrapy] ERROR: Error processing {'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7713',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:43:36 [scrapy] ERROR: Error processing {'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121925',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:44:07 [scrapy] ERROR: Error processing {'appid': u'53109',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1076',
 'developer': u'\u4e07\u8fbe\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'54516', u'9531', u'33976', u'67284'],
 'title': u'\u98de\u51e1',
 'update_time': u'2016-06-02',
 'version': u'4.2.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:44:37 [scrapy] ERROR: Error processing {'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35096',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:45:07 [scrapy] ERROR: Error processing {'appid': u'1117',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '9272',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [u'32351', u'58458', u'50401', u'75942'],
 'title': u'QQ\u7a7a\u95f4',
 'update_time': u'2016-06-08',
 'version': u'6.5.4.288'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:45:37 [scrapy] ERROR: Error processing {'appid': u'50816',
 'category': u'\u56fe\u4e66\u9605\u8bfb',
 'count': '44497',
 'developer': u'\u6df1\u5733\u5e02\u5b9c\u641c\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'57598', u'113904', u'363008', u'80324'],
 'groupid': u'7',
 'rating': u'9',
 'related_recommended': [u'80596', u'71089', u'11121', u'87667'],
 'title': u'\u5b9c\u641c\u5c0f\u8bf4',
 'update_time': u'2016-05-30',
 'version': u'2.10.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:45:37 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:45:37 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:45:37 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/89336> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:45:37 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5027> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:45:37 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:45:37 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:45:37 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:45:37 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71600> (referer: http://app.mi.com/topList?page=1)
2016-06-18 09:45:37 [scrapy] INFO: Crawled 28 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:46:07 [scrapy] ERROR: Error processing {'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12659',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:46:37 [scrapy] ERROR: Error processing {'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9808',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:47:07 [scrapy] ERROR: Error processing {'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '254506',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:47:37 [scrapy] ERROR: Error processing {'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9075',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:48:07 [scrapy] ERROR: Error processing {'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12136',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:48:37 [scrapy] ERROR: Error processing {'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22376',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:49:07 [scrapy] ERROR: Error processing {'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10998',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:49:37 [scrapy] ERROR: Error processing {'appid': u'405279',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '43',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'2',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000\u52a9\u624b',
 'update_time': u'2016-06-06',
 'version': u'1.0.1.603'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:49:37 [scrapy] INFO: Crawled 28 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:49:37 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/1326> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/1326 took longer than 180.0 seconds..
2016-06-18 09:49:37 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/1127> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/1127 took longer than 180.0 seconds..
2016-06-18 09:49:37 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/121542> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/121542 took longer than 180.0 seconds..
2016-06-18 09:49:37 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/29> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/29 took longer than 180.0 seconds..
2016-06-18 09:49:37 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/24269> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/24269 took longer than 180.0 seconds..
2016-06-18 09:49:37 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/18076> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/18076 took longer than 180.0 seconds..
2016-06-18 09:49:37 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/8543> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/8543 took longer than 180.0 seconds..
2016-06-18 09:49:37 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/4888> (failed 1 times): User timeout caused connection failure: Getting http://app.mi.com/detail/4888 took longer than 180.0 seconds..
2016-06-18 09:50:07 [scrapy] ERROR: Error processing {'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3450',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:50:37 [scrapy] ERROR: Error processing {'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24346',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:51:07 [scrapy] ERROR: Error processing {'appid': u'89336',
 'category': u'\u6a21\u62df\u7ecf\u8425',
 'count': '9120',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8\u73e0\u6d77\u5206\u516c\u53f8',
 'developer_recommended': [u'100739', u'70869', u'404995', u'364950'],
 'groupid': u'29',
 'rating': u'9',
 'related_recommended': [u'89462', u'96776', u'72342', u'94160'],
 'title': u'\u591a\u73a9\u6211\u7684\u4e16\u754c\u76d2\u5b50',
 'update_time': u'2016-06-08',
 'version': u'1.6.26'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:51:37 [scrapy] ERROR: Error processing {'appid': u'5027',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1225',
 'developer': u'\u5357\u4eac\u82cf\u5b81\u6613\u8d2d\u7535\u5b50\u5546\u52a1\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'49061'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'56049', u'11597', u'9531', u'51027'],
 'title': u'\u82cf\u5b81\u6613\u8d2d-\u5e74\u4e2d\u5927\u4fc3',
 'update_time': u'2016-06-17',
 'version': u'4.2.6'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:52:07 [scrapy] ERROR: Error processing {'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17806',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:52:37 [scrapy] ERROR: Error processing {'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28031',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:53:08 [scrapy] ERROR: Error processing {'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10673',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:53:38 [scrapy] ERROR: Error processing {'appid': u'71600',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '2013',
 'developer': u'\u5317\u4eac\u5c0f\u5ea6\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'81775'],
 'groupid': u'4',
 'rating': u'10',
 'related_recommended': [u'98717', u'2133', u'56249', u'48956'],
 'title': u'\u767e\u5ea6\u5916\u5356',
 'update_time': u'2016-06-16',
 'version': u'3.9.0'}
Traceback (most recent call last):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/twisted/internet/defer.py", line 588, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py", line 152, in process_item
    search_result = self.collection.find_one(result)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/collection.py", line 1006, in find_one
    for result in cursor.limit(-1):
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1090, in next
    if len(self.__data) or self._refresh():
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 1012, in _refresh
    self.__read_concern))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/cursor.py", line 850, in __send_message
    **kwargs)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/mongo_client.py", line 781, in _send_message_with_response
    server = topology.select_server(selector)
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 142, in select_server
    address))
  File "/home/x/Project/PycharmProjects/crawler/myapp/local/lib/python2.7/site-packages/pymongo/topology.py", line 118, in select_servers
    self._error_message(selector))
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
2016-06-18 09:53:38 [scrapy] INFO: Crawled 28 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 09:53:38 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/497> (failed 1 times): User timeout caused connection failure.
2016-06-18 09:53:38 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/329> (failed 1 times): User timeout caused connection failure.
2016-06-18 09:53:38 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/346> (failed 1 times): User timeout caused connection failure.
2016-06-18 09:53:38 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/1363> (failed 1 times): User timeout caused connection failure.
2016-06-18 09:53:38 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/7055> (failed 1 times): User timeout caused connection failure.
2016-06-18 09:53:38 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/1109> (failed 1 times): User timeout caused connection failure.
2016-06-18 09:53:38 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/48217> (failed 1 times): User timeout caused connection failure.
2016-06-18 09:53:38 [scrapy] DEBUG: Retrying <GET http://app.mi.com/detail/1357> (failed 1 times): User timeout caused connection failure.
2016-06-18 10:25:47 [scrapy] INFO: Received SIGTERM, shutting down gracefully. Send again to force 
2016-06-18 10:25:47 [scrapy] INFO: Closing spider (shutdown)
2016-06-18 10:33:55 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-18 10:33:55 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-18 10:33:55 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-18 10:33:55 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-18 10:33:55 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-18 10:33:56 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-18 10:33:56 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiMongoDBPipeline']
2016-06-18 10:33:56 [scrapy] INFO: Spider opened
2016-06-18 10:33:56 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 10:33:56 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-18 10:33:56 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-18 10:33:57 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-18 10:33:57 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:57 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:160: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  level=log.DEBUG, spider=spider)

2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1359>
{'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133636',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/48217> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/332>
{'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2666',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/48217>
{'appid': u'48217',
 'category': u'\u8dd1\u9177\u95ef\u5173',
 'count': '113196',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'329513', u'54227', u'77714', u'33013'],
 'groupid': u'26',
 'rating': u'7',
 'related_recommended': [u'45078', u'44197', u'57492', u'68657'],
 'title': u'\u5929\u5929\u9177\u8dd1',
 'update_time': u'2016-06-03',
 'version': u'1.0.34.0'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/125>
{'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54036',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'396378', u'118', u'97530', u'22909'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/329>
{'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321567',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/346>
{'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22567',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1363>
{'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29820',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/7055>
{'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10205',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1109>
{'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69615',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/50816> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1117> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1110>
{'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37053',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1984', u'69660', u'330724', u'360'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/109>
{'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '75028',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/50816>
{'appid': u'50816',
 'category': u'\u56fe\u4e66\u9605\u8bfb',
 'count': '44502',
 'developer': u'\u6df1\u5733\u5e02\u5b9c\u641c\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'57598', u'113904', u'363008', u'80324'],
 'groupid': u'7',
 'rating': u'9',
 'related_recommended': [u'80596', u'71089', u'11121', u'87667'],
 'title': u'\u5b9c\u641c\u5c0f\u8bf4',
 'update_time': u'2016-05-30',
 'version': u'2.10.0'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1131>
{'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49093',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/22704>
{'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22378',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1294>
{'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35097',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/10411>
{'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7713',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1117>
{'appid': u'1117',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '9272',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [u'32351', u'58458', u'50401', u'75942'],
 'title': u'QQ\u7a7a\u95f4',
 'update_time': u'2016-06-08',
 'version': u'6.5.4.288'}
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/89336> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5027> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71600> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/323>
{'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3450',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/89336>
{'appid': u'89336',
 'category': u'\u6a21\u62df\u7ecf\u8425',
 'count': '9120',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8\u73e0\u6d77\u5206\u516c\u53f8',
 'developer_recommended': [u'100739', u'70869', u'404995', u'364950'],
 'groupid': u'29',
 'rating': u'9',
 'related_recommended': [u'89462', u'96776', u'72342', u'94160'],
 'title': u'\u591a\u73a9\u6211\u7684\u4e16\u754c\u76d2\u5b50',
 'update_time': u'2016-06-08',
 'version': u'1.6.26'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1338>
{'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24346',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5027>
{'appid': u'5027',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1225',
 'developer': u'\u5357\u4eac\u82cf\u5b81\u6613\u8d2d\u7535\u5b50\u5546\u52a1\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'49061'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'56049', u'11597', u'9531', u'51027'],
 'title': u'\u82cf\u5b81\u6613\u8d2d-\u5e74\u4e2d\u5927\u4fc3',
 'update_time': u'2016-06-17',
 'version': u'4.2.6'}
2016-06-18 10:33:58 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:58 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29837>
{'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28032',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/9744>
{'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10673',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71600>
{'appid': u'71600',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '2013',
 'developer': u'\u5317\u4eac\u5c0f\u5ea6\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'81775'],
 'groupid': u'4',
 'rating': u'10',
 'related_recommended': [u'98717', u'2133', u'56249', u'48956'],
 'title': u'\u767e\u5ea6\u5916\u5356',
 'update_time': u'2016-06-16',
 'version': u'3.9.0'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/118>
{'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17807',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/121542> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/18076> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/24269> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/121542>
{'appid': u'121542',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '15335',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u7a7f\u8d8a\u706b\u7ebf\uff1a\u67aa\u6218\u738b\u8005',
 'update_time': u'2016-04-28',
 'version': u'1.0.7.60'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1127>
{'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '342349',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29>
{'appid': u'29',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '21286',
 'developer': u'\u5317\u4eac\u641c\u72d7\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1284', u'352553', u'33664', u'37993'],
 'groupid': u'5',
 'rating': u'9',
 'related_recommended': [u'33664', u'37993', u'52597', u'3021'],
 'title': u'\u641c\u72d7\u8f93\u5165\u6cd5',
 'update_time': u'2016-05-27',
 'version': u'8.2.1'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/18076>
{'appid': u'18076',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '11975',
 'developer': u'\u62c9\u624e\u65af\u7f51\u7edc\u79d1\u6280\uff08\u4e0a\u6d77\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'346753', u'120094', u'119616'],
 'groupid': u'4',
 'rating': u'8',
 'related_recommended': [u'48956', u'98717', u'56249', u'2133'],
 'title': u'\u997f\u4e86\u4e48',
 'update_time': u'2016-06-12',
 'version': u'5.11'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1326>
{'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147994',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/24269>
{'appid': u'24269',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '63277',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'1326', u'110320', u'293149'],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'94392', u'91399', u'33662', u'63932'],
 'title': u'\u7f8e\u989c\u76f8\u673a',
 'update_time': u'2016-06-13',
 'version': u'4.6.5.0'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/8543>
{'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7449',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4888>
{'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2175',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/53109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/405279> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/53109>
{'appid': u'53109',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1076',
 'developer': u'\u4e07\u8fbe\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'54516', u'9531', u'33976', u'67284'],
 'title': u'\u98de\u51e1',
 'update_time': u'2016-06-02',
 'version': u'4.2.1.0'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1122>
{'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121928',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/405279>
{'appid': u'405279',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '44',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'2',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000\u52a9\u624b',
 'update_time': u'2016-06-06',
 'version': u'1.0.1.603'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1023>
{'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '254517',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5314>
{'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12660',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/96928>
{'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9809',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4928>
{'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12136',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/112109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/98>
{'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9075',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/39086>
{'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10998',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1045>
{'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '220408',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1357>
{'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18216',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/112109>
{'appid': u'112109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '1067',
 'developer': u'MIUI\u8bba\u575b',
 'developer_recommended': [],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [],
 'title': u'MIUI\u8bba\u575b',
 'update_time': u'2016-06-06',
 'version': u'2.6.1'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/108048>
{'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26452',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
2016-06-18 10:33:59 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:33:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71936>
{'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4204',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
2016-06-18 10:33:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:34:00 [scrapy] DEBUG: Item added to MongoDB database!
2016-06-18 10:34:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/497>
{'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93173',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
2016-06-18 10:34:00 [scrapy] INFO: Closing spider (finished)
2016-06-18 10:34:00 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15348,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 321697,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 18, 17, 34, 0, 33277),
 'item_scraped_count': 48,
 'log_count/DEBUG': 148,
 'log_count/INFO': 7,
 'log_count/WARNING': 2,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 18, 17, 33, 56, 114290)}
2016-06-18 10:34:00 [scrapy] INFO: Spider closed (finished)
2016-06-18 10:34:57 [scrapy] INFO: Scrapy 1.1.0 started (bot: xiaomiapp)
2016-06-18 10:34:57 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'xiaomiapp.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['xiaomiapp.spiders'], 'LOG_FILE': 'scrapy.log', 'BOT_NAME': 'xiaomiapp'}
2016-06-18 10:34:57 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2016-06-18 10:34:57 [scrapy] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2016-06-18 10:34:57 [scrapy] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2016-06-18 10:34:57 [py.warnings] WARNING: /home/x/Project/PycharmProjects/crawler/myapp/xiaomiapp/xiaomiapp/pipelines.py:15: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2016-06-18 10:34:57 [scrapy] INFO: Enabled item pipelines:
['xiaomiapp.pipelines.XiaomiMongoDBPipeline']
2016-06-18 10:34:57 [scrapy] INFO: Spider opened
2016-06-18 10:34:57 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2016-06-18 10:34:57 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2016-06-18 10:34:58 [scrapy] DEBUG: Crawled (404) <GET http://app.mi.com/robots.txt> (referer: None)
2016-06-18 10:34:58 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: None)
2016-06-18 10:34:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/topList?page=1> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:34:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1110> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:34:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1131> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:34:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/50816> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:34:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1294> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:34:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/10411> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:34:59 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1122> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:34:59 [root] INFO: Skip duplicates
2016-06-18 10:34:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1110>
{'appid': u'1110',
 'category': u'\u91d1\u878d\u7406\u8d22',
 'count': '37053',
 'developer': u'\u652f\u4ed8\u5b9d\uff08\u4e2d\u56fd\uff09\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'59991', u'53514'],
 'groupid': u'1',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u652f\u4ed8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'9.6.8.053103'}
2016-06-18 10:34:59 [root] INFO: Skip duplicates
2016-06-18 10:34:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1131>
{'appid': u'1131',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '49093',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'11659', u'31250', u'7', u'301'],
 'title': u'QQ\u97f3\u4e50',
 'update_time': u'2016-06-07',
 'version': u'6.1.1.10'}
2016-06-18 10:34:59 [root] INFO: Skip duplicates
2016-06-18 10:34:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/50816>
{'appid': u'50816',
 'category': u'\u56fe\u4e66\u9605\u8bfb',
 'count': '44502',
 'developer': u'\u6df1\u5733\u5e02\u5b9c\u641c\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'57598', u'113904', u'363008', u'80324'],
 'groupid': u'7',
 'rating': u'9',
 'related_recommended': [u'80596', u'71089', u'11121', u'87667'],
 'title': u'\u5b9c\u641c\u5c0f\u8bf4',
 'update_time': u'2016-05-30',
 'version': u'2.10.0'}
2016-06-18 10:34:59 [root] INFO: Skip duplicates
2016-06-18 10:34:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1294>
{'appid': u'1294',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '35097',
 'developer': u'\u4e50\u89c6\u7f51\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u80a1\u4efd\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'369096', u'113128', u'45617', u'378877'],
 'groupid': u'27',
 'rating': u'7',
 'related_recommended': [u'50508', u'2889', u'3581', u'125'],
 'title': u'\u4e50\u89c6\u89c6\u9891-\u7ffb\u8bd1\u5b98',
 'update_time': u'2016-05-19',
 'version': u'6.6.1'}
2016-06-18 10:34:59 [root] INFO: Skip duplicates
2016-06-18 10:34:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/10411>
{'appid': u'10411',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7713',
 'developer': u'\u5317\u4eac\u5c0f\u6854\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'8914', u'103203', u'146850'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'4958', u'34162', u'79713', u'81823'],
 'title': u'\u6ef4\u6ef4\u51fa\u884c',
 'update_time': u'2016-06-16',
 'version': u'4.3.8'}
2016-06-18 10:34:59 [root] INFO: Skip duplicates
2016-06-18 10:34:59 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1122>
{'appid': u'1122',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '121929',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6df1\u5733\uff09\u6709\u9650\u516c\u53f8\u5e7f\u5dde\u5206\u516c\u53f8',
 'developer_recommended': [u'336025', u'109885', u'20441'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'52029', u'297', u'1359', u'82846'],
 'title': u'\u5fae\u4fe1',
 'update_time': u'2016-06-06',
 'version': u'6.3.18'}
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/53109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/96928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1023> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4928> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/405279> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/98> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/39086> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/53109>
{'appid': u'53109',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1076',
 'developer': u'\u4e07\u8fbe\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'54516', u'9531', u'33976', u'67284'],
 'title': u'\u98de\u51e1',
 'update_time': u'2016-06-02',
 'version': u'4.2.1.0'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/96928>
{'appid': u'96928',
 'category': u'\u4f11\u95f2\u521b\u610f',
 'count': '9809',
 'developer': u'superpop',
 'developer_recommended': [],
 'groupid': u'23',
 'rating': u'8',
 'related_recommended': [u'23418', u'99376', u'72342', u'89462'],
 'title': u'\u7403\u7403\u5927\u4f5c\u6218',
 'update_time': u'2016-04-22',
 'version': u'4.0.2'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1023>
{'appid': u'1023',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '254519',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'16116', u'2086', u'452', u'307'],
 'title': u'\u624b\u673a\u6dd8\u5b9d',
 'update_time': u'2016-06-02',
 'version': u'5.8.0'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4928>
{'appid': u'4928',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '12136',
 'developer': u'\u4e0a\u6d77\u4e2d\u5f66\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'80518', u'59053', u'11867'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'72617', u'96743', u'79984', u'360'],
 'title': u'\u8fd4\u5229',
 'update_time': u'2016-06-12',
 'version': u'5.1.0'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/405279>
{'appid': u'405279',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '44',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'71936', u'57492'],
 'groupid': u'2',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000\u52a9\u624b',
 'update_time': u'2016-06-06',
 'version': u'1.0.1.603'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/98>
{'appid': u'98',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '9075',
 'developer': u'\u5317\u4eac\u4e09\u5feb\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'103794', u'9037', u'55992', u'103515'],
 'groupid': u'9',
 'rating': u'8',
 'related_recommended': [u'55992', u'56249', u'1141', u'1046'],
 'title': u'\u7f8e\u56e2',
 'update_time': u'2016-06-02',
 'version': u'6.9.2'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/39086>
{'appid': u'39086',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10998',
 'developer': u'\u6e56\u5357\u5feb\u4e50\u9633\u5149\u4e92\u52a8\u5a31\u4e50\u4f20\u5a92\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'405228', u'156423', u'73276'],
 'groupid': u'27',
 'rating': u'4',
 'related_recommended': [u'47269', u'69754', u'1132', u'16590'],
 'title': u'\u8292\u679cTV',
 'update_time': u'2016-05-26',
 'version': u'4.6.9'}
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/22704> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71936> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5027> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/323> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/89336> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1338> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/22704>
{'appid': u'22704',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '22378',
 'developer': u'\u5317\u4eac\u4e94\u516b\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'257650', u'117457', u'61175', u'105478'],
 'groupid': u'4',
 'rating': u'9',
 'related_recommended': [u'69736', u'61175', u'3726', u'99959'],
 'title': u'58\u540c\u57ce',
 'update_time': u'2016-06-17',
 'version': u'7.0.6.1'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71936>
{'appid': u'71936',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '4204',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'57492', u'235034'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'72149', u'84504', u'54227', u'26484'],
 'title': u'\u5168\u6c11K\u6b4c',
 'update_time': u'2016-06-13',
 'version': u'3.5.8.278'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5027>
{'appid': u'5027',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '1225',
 'developer': u'\u5357\u4eac\u82cf\u5b81\u6613\u8d2d\u7535\u5b50\u5546\u52a1\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'49061'],
 'groupid': u'9',
 'rating': u'7',
 'related_recommended': [u'56049', u'11597', u'9531', u'51027'],
 'title': u'\u82cf\u5b81\u6613\u8d2d-\u5e74\u4e2d\u5927\u4fc3',
 'update_time': u'2016-06-17',
 'version': u'4.2.6'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/323>
{'appid': u'323',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '3450',
 'developer': u'\u5c0f\u7c73\u79d1\u6280',
 'developer_recommended': [u'68548', u'121089', u'153601', u'200058'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'1008', u'99959', u'1127', u'32323'],
 'title': u'\u7c73\u804a',
 'update_time': u'2016-05-13',
 'version': u'7.4.66'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/89336>
{'appid': u'89336',
 'category': u'\u6a21\u62df\u7ecf\u8425',
 'count': '9120',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8\u73e0\u6d77\u5206\u516c\u53f8',
 'developer_recommended': [u'100739', u'70869', u'404995', u'364950'],
 'groupid': u'29',
 'rating': u'9',
 'related_recommended': [u'89462', u'96776', u'72342', u'94160'],
 'title': u'\u591a\u73a9\u6211\u7684\u4e16\u754c\u76d2\u5b50',
 'update_time': u'2016-06-08',
 'version': u'1.6.26'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1338>
{'appid': u'1338',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '24346',
 'developer': u'\u9ad8\u5fb7\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'114080', u'93699', u'46455', u'201840'],
 'groupid': u'3',
 'rating': u'9',
 'related_recommended': [u'32323', u'46455', u'4959', u'405'],
 'title': u'\u9ad8\u5fb7\u5730\u56fe',
 'update_time': u'2016-05-25',
 'version': u'7.7.0.0.2036'}
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29837> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1127> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/9744> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/71600> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1326> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/118> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29837>
{'appid': u'29837',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '28032',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'5',
 'rating': u'8',
 'related_recommended': [u'21976', u'68657', u'27650', u'62091'],
 'title': u'QQ\u5b89\u5168\u4e2d\u5fc3',
 'update_time': u'2016-05-30',
 'version': u'6.7.2'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1127>
{'appid': u'1127',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '342349',
 'developer': u'\u5fae\u68a6\u521b\u79d1\u7f51\u7edc\u6280\u672f\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'379843', u'283', u'97015'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'34507', u'16938', u'58458', u'323'],
 'title': u'\u5fae\u535a',
 'update_time': u'2016-06-17',
 'version': u'6.6.1'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/9744>
{'appid': u'9744',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '10673',
 'developer': u'\u6df1\u5733\u5e02\u8fc5\u96f7\u7f51\u7edc\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'414306', u'329235', u'89937', u'115378'],
 'groupid': u'27',
 'rating': u'3',
 'related_recommended': [u'44238', u'310', u'56059', u'1098'],
 'title': u'\u8fc5\u96f7',
 'update_time': u'2016-05-28',
 'version': u'5.17.2.4000'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/71600>
{'appid': u'71600',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '2013',
 'developer': u'\u5317\u4eac\u5c0f\u5ea6\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'81775'],
 'groupid': u'4',
 'rating': u'10',
 'related_recommended': [u'98717', u'2133', u'56249', u'48956'],
 'title': u'\u767e\u5ea6\u5916\u5356',
 'update_time': u'2016-06-16',
 'version': u'3.9.0'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1326>
{'appid': u'1326',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '147994',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'110320', u'293149', u'24269'],
 'groupid': u'6',
 'rating': u'10',
 'related_recommended': [u'1057', u'81532', u'33695', u'85051'],
 'title': u'\u7f8e\u56fe\u79c0\u79c0',
 'update_time': u'2016-06-16',
 'version': u'5.1.0.0'}
2016-06-18 10:35:00 [root] INFO: Skip duplicates
2016-06-18 10:35:00 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/118>
{'appid': u'118',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '17807',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'50219', u'402506', u'9519'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'125', u'155', u'310', u'1121'],
 'title': u'\u7231\u5947\u827aPPS',
 'update_time': u'2016-05-31',
 'version': u'5.5.0'}
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/121542> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1357> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/29> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/24269> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/18076> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/8543> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/4888> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/5314> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/121542>
{'appid': u'121542',
 'category': u'\u52a8\u4f5c\u67aa\u6218',
 'count': '15335',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'17',
 'rating': u'8',
 'related_recommended': [],
 'title': u'\u7a7f\u8d8a\u706b\u7ebf\uff1a\u67aa\u6218\u738b\u8005',
 'update_time': u'2016-04-28',
 'version': u'1.0.7.60'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1357>
{'appid': u'1357',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '18216',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8\u5317\u4eac\u5206\u516c\u53f8',
 'developer_recommended': [u'39312', u'2241', u'100053', u'7012'],
 'groupid': u'27',
 'rating': u'5',
 'related_recommended': [u'181', u'2889', u'3581', u'897'],
 'title': u'\u817e\u8baf\u89c6\u9891',
 'update_time': u'2016-06-02',
 'version': u'4.8.5.10223'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/29>
{'appid': u'29',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '21286',
 'developer': u'\u5317\u4eac\u641c\u72d7\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'1284', u'3021', u'37993', u'168890'],
 'groupid': u'5',
 'rating': u'9',
 'related_recommended': [u'33664', u'37993', u'52597', u'3021'],
 'title': u'\u641c\u72d7\u8f93\u5165\u6cd5',
 'update_time': u'2016-05-27',
 'version': u'8.2.1'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/24269>
{'appid': u'24269',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '63277',
 'developer': u'\u53a6\u95e8\u7f8e\u56fe\u4e4b\u5bb6\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'63447', u'1326', u'110320', u'293149'],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'94392', u'91399', u'33662', u'63932'],
 'title': u'\u7f8e\u989c\u76f8\u673a',
 'update_time': u'2016-06-13',
 'version': u'4.6.5.0'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/18076>
{'appid': u'18076',
 'category': u'\u5c45\u5bb6\u751f\u6d3b',
 'count': '11975',
 'developer': u'\u62c9\u624e\u65af\u7f51\u7edc\u79d1\u6280\uff08\u4e0a\u6d77\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'346753', u'120094', u'119616'],
 'groupid': u'4',
 'rating': u'8',
 'related_recommended': [u'48956', u'98717', u'56249', u'2133'],
 'title': u'\u997f\u4e86\u4e48',
 'update_time': u'2016-06-12',
 'version': u'5.11'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/8543>
{'appid': u'8543',
 'category': u'\u65c5\u884c\u4ea4\u901a',
 'count': '7449',
 'developer': u'\u4e0a\u6d77\u96fe\u535a\u4fe1\u606f\u6280\u672f\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'245241'],
 'groupid': u'3',
 'rating': u'6',
 'related_recommended': [u'11150', u'10411', u'4958', u'34162'],
 'title': u'\u4f18\u6b65 - Uber',
 'update_time': u'2016-06-13',
 'version': u'3.107.1'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/4888>
{'appid': u'4888',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2175',
 'developer': u'\u6dd8\u5b9d\uff08\u4e2d\u56fd\uff09\u8f6f\u4ef6\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'75339', u'113506', u'1984', u'69660'],
 'groupid': u'9',
 'rating': u'4',
 'related_recommended': [u'15228', u'99959', u'9531', u'11597'],
 'title': u'\u5929\u732b',
 'update_time': u'2016-05-26',
 'version': u'5.19.1'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/5314>
{'appid': u'5314',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '12660',
 'developer': u'\u767e\u5ea6\u5728\u7ebf\u7f51\u7edc\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'321', u'10025', u'192', u'378879'],
 'groupid': u'5',
 'rating': u'6',
 'related_recommended': [u'82805', u'57257', u'5930', u'57983'],
 'title': u'\u767e\u5ea6\u4e91',
 'update_time': u'2016-06-07',
 'version': u'7.13.0'}
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/497> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1363> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/7055> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/48217> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/346> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/497>
{'appid': u'497',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '93173',
 'developer': u'\u5317\u4eac\u767e\u5ea6\u7f51\u8baf\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'73695', u'78008'],
 'groupid': u'9',
 'rating': u'10',
 'related_recommended': [u'73695', u'2133', u'1300', u'39588'],
 'title': u'\u767e\u5ea6\u7cef\u7c73-6\u5468\u5e74',
 'update_time': u'2016-06-14',
 'version': u'6.6.2'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1363>
{'appid': u'1363',
 'category': u'\u5b9e\u7528\u5de5\u5177',
 'count': '29820',
 'developer': u'\u4f18\u89c6\u79d1\u6280\uff08\u4e2d\u56fd\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'5',
 'rating': u'7',
 'related_recommended': [],
 'title': u'UC\u6d4f\u89c8\u5668',
 'update_time': u'2016-06-15',
 'version': u'10.10.3.810'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/7055>
{'appid': u'7055',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '10205',
 'developer': u'\u5e7f\u5dde\u552f\u54c1\u4f1a\u4fe1\u606f\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'89001', u'103342', u'80107', u'52475'],
 'groupid': u'9',
 'rating': u'9',
 'related_recommended': [u'52475', u'11597', u'39120', u'19873'],
 'title': u'\u552f\u54c1\u4f1a-\u5e74\u4e2d\u7279\u5356',
 'update_time': u'2016-06-13',
 'version': u'5.21.7'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1109>
{'appid': u'1109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '69615',
 'developer': u'\u5e7f\u5dde\u534e\u591a\u7f51\u7edc\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'51833', u'276471', u'361787', u'209755'],
 'groupid': u'2',
 'rating': u'9',
 'related_recommended': [u'62957', u'59208', u'86608', u'35295'],
 'title': u'YY',
 'update_time': u'2016-06-15',
 'version': u'5.5.2'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/48217>
{'appid': u'48217',
 'category': u'\u8dd1\u9177\u95ef\u5173',
 'count': '113196',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'329513', u'54227', u'77714', u'33013'],
 'groupid': u'26',
 'rating': u'7',
 'related_recommended': [u'45078', u'44197', u'57492', u'68657'],
 'title': u'\u5929\u5929\u9177\u8dd1',
 'update_time': u'2016-06-03',
 'version': u'1.0.34.0'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/346>
{'appid': u'346',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '22567',
 'developer': u'\u5317\u4eac\u964c\u964c\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'319980'],
 'groupid': u'2',
 'rating': u'6',
 'related_recommended': [u'129', u'19174', u'68656', u'61518'],
 'title': u'\u964c\u964c',
 'update_time': u'2016-06-06',
 'version': u'6.9.2'}
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/329> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1045> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/112109> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/108048> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1117> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/1359> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/332> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/329>
{'appid': u'329',
 'category': u'\u6444\u5f71\u6444\u50cf',
 'count': '321567',
 'developer': u'\u5317\u4eac\u4e00\u7b11\u79d1\u6280\u53d1\u5c55\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'6',
 'rating': u'9',
 'related_recommended': [u'2027', u'91399', u'26484', u'63932'],
 'title': u'\u5feb\u624b',
 'update_time': u'2016-05-26',
 'version': u'4.45.0.1504'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/109>
{'appid': u'109',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '75028',
 'developer': u'\u5e7f\u5dde\u9177\u72d7\u8ba1\u7b97\u673a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'45243', u'50634', u'44900', u'31233'],
 'groupid': u'27',
 'rating': u'6',
 'related_recommended': [u'31233', u'11659', u'31250', u'1131'],
 'title': u'\u9177\u72d7\u97f3\u4e50',
 'update_time': u'2016-06-08',
 'version': u'8.1.2'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1045>
{'appid': u'1045',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '220408',
 'developer': u'\u5408\u4e00\u4fe1\u606f\u6280\u672f\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'394794', u'325526', u'187579', u'57429'],
 'groupid': u'27',
 'rating': u'9',
 'related_recommended': [u'2095', u'50508', u'69754', u'51833'],
 'title': u'\u4f18\u9177\u89c6\u9891',
 'update_time': u'2016-06-07',
 'version': u'5.7'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/112109>
{'appid': u'112109',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '1067',
 'developer': u'MIUI\u8bba\u575b',
 'developer_recommended': [],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [],
 'title': u'MIUI\u8bba\u575b',
 'update_time': u'2016-06-06',
 'version': u'2.6.1'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/108048>
{'appid': u'108048',
 'category': u'\u7f51\u6e38RPG',
 'count': '26452',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'19',
 'rating': u'7',
 'related_recommended': [],
 'title': u'\u738b\u8005\u8363\u8000',
 'update_time': u'2016-05-13',
 'version': u'1.12.1.7'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1117>
{'appid': u'1117',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '9272',
 'developer': u'\u817e\u8baf\u79d1\u6280\uff08\u6210\u90fd)\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'96199', u'297', u'39312'],
 'groupid': u'2',
 'rating': u'4',
 'related_recommended': [u'32351', u'58458', u'50401', u'75942'],
 'title': u'QQ\u7a7a\u95f4',
 'update_time': u'2016-06-08',
 'version': u'6.5.4.288'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/1359>
{'appid': u'1359',
 'category': u'\u804a\u5929\u793e\u4ea4',
 'count': '133637',
 'developer': u'\u6df1\u5733\u5e02\u817e\u8baf\u8ba1\u7b97\u673a\u7cfb\u7edf\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'419901', u'100053', u'184154', u'289530'],
 'groupid': u'2',
 'rating': u'5',
 'related_recommended': [u'58458', u'1109', u'315', u'7464'],
 'title': u'QQ',
 'update_time': u'2016-05-27',
 'version': u'6.3.7'}
2016-06-18 10:35:01 [root] INFO: Skip duplicates
2016-06-18 10:35:01 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/332>
{'appid': u'332',
 'category': u'\u65f6\u5c1a\u8d2d\u7269',
 'count': '2666',
 'developer': u'\u5317\u4eac\u4eac\u4e1c\u4e16\u7eaa\u8d38\u6613\u6709\u9650\u516c\u53f8',
 'developer_recommended': [],
 'groupid': u'9',
 'rating': u'5',
 'related_recommended': [u'69662', u'58628', u'33976', u'9531'],
 'title': u'\u4eac\u4e1c',
 'update_time': u'2016-05-17',
 'version': u'5.1.0'}
2016-06-18 10:35:02 [scrapy] DEBUG: Crawled (200) <GET http://app.mi.com/detail/125> (referer: http://app.mi.com/topList?page=1)
2016-06-18 10:35:02 [root] INFO: Skip duplicates
2016-06-18 10:35:02 [scrapy] DEBUG: Scraped from <200 http://app.mi.com/detail/125>
{'appid': u'125',
 'category': u'\u5f71\u97f3\u89c6\u542c',
 'count': '54036',
 'developer': u'\u5317\u4eac\u7231\u5947\u827a\u79d1\u6280\u6709\u9650\u516c\u53f8',
 'developer_recommended': [u'192', u'378879', u'1100', u'98666'],
 'groupid': u'27',
 'rating': u'8',
 'related_recommended': [u'118', u'39086', u'2095', u'155'],
 'title': u'\u7231\u5947\u827a-\u8dd1\u75374',
 'update_time': u'2016-06-02',
 'version': u'7.5.1'}
2016-06-18 10:35:02 [scrapy] INFO: Closing spider (finished)
2016-06-18 10:35:02 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 15348,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 321602,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 50,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2016, 6, 18, 17, 35, 2, 259594),
 'item_scraped_count': 48,
 'log_count/DEBUG': 100,
 'log_count/INFO': 55,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 51,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2016, 6, 18, 17, 34, 57, 722037)}
2016-06-18 10:35:02 [scrapy] INFO: Spider closed (finished)
